{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04ddd131",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Fetching 5 files: 100%|██████████| 5/5 [02:06<00:00, 25.40s/it]\n",
      "/Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/transformers/convert_slow_tokenizer.py:566: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Musk => Person\n",
      "analysts => Person\n",
      "margin compression => Business Metric\n",
      "demand => Business Metric\n"
     ]
    }
   ],
   "source": [
    "from gliner import GLiNER\n",
    "\n",
    "model = GLiNER.from_pretrained(\"urchade/gliner_medium-v2.1\")\n",
    "\n",
    "text = \"While Musk pushes for rapid expansion, analysts worry about margin compression and demand.\"\n",
    "\n",
    "# Define CUSTOM labels on the fly\n",
    "labels = [\"Person\", \"Business Metric\", \"Strategic Move\"]\n",
    "\n",
    "entities = model.predict_entities(text, labels)\n",
    "\n",
    "for entity in entities:\n",
    "    print(f\"{entity['text']} => {entity['label']}\")\n",
    "\n",
    "# Output:\n",
    "# Musk => Person\n",
    "# rapid expansion => Strategic Move\n",
    "# margin compression => Business Metric\n",
    "# demand => Business Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df5314b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Air Force One => object\n",
      "Joint Base Andrews => place\n",
      "Maryland => place\n",
      "Press Secretary Karoline Leavitt => person\n",
      "Trump => person\n",
      "Trump => person\n",
      "World Economic Forum => place\n",
      "Trump => person\n"
     ]
    }
   ],
   "source": [
    "new_text = \"\"\"Air Force One returned to Joint Base Andrews, an air base in Maryland, out of an abundance of caution, Press Secretary Karoline Leavitt said. It landed shortly after 11 pm (local time), after about an hour and 20 minutes in the air.\n",
    "Journalists travelling with Trump reported that the lights in the cabin went out briefly after takeoff, as per the news agency AFP.\n",
    "Trump and his entourage resumed their trip to the World Economic Forum after switching to another plane. Trump took off two-and-a-half hours after his initial departure. He is scheduled to arrive on Wednesday and leave on Thursday.\"\"\"\n",
    "labels = ['person','place','object','']\n",
    "#labels = [\"Person\", \"Business Metric\", \"Strategic Move\"]\n",
    "entities = model.predict_entities(new_text, labels)\n",
    "\n",
    "for entity in entities:\n",
    "    print(f\"{entity['text']} => {entity['label']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49eda62e",
   "metadata": {},
   "source": [
    " This is interesting, different labels are leading it to classify differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1056edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donald Trump => person\n",
      "Davos => place\n",
      "Switzerland => place\n",
      "Wednesday => time\n",
      "Greenland => place\n",
      "European protests => political event\n",
      "Tuesday => time\n",
      "World Economic Forum => meeting\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\" U.S. President Donald Trump barrels into Davos, Switzerland, on Wednesday, where he is likely to escalate his push for acquiring Greenland despite European protests in the biggest fraying of transatlantic ties in decades.\n",
    "Trump, who marked the end of his turbulent first year in office on Tuesday, is expected to overshadow the annual World Economic Forum (WEF) gathering where global elites discuss economic and political trends in the Swiss mountain resort.\n",
    "\"\"\"\n",
    "labels = ['person','place','object','time','political event','meeting']\n",
    "#labels = [\"Person\", \"Business Metric\", \"Strategic Move\"]\n",
    "entities = model.predict_entities(text, labels)\n",
    "\n",
    "for entity in entities:\n",
    "    print(f\"{entity['text']} => {entity['label']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13b6d82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donald Trump => Donald Trump\n",
      "Davos => Davos\n",
      "Switzerland => Switzerland\n",
      "European protests => European Protests\n",
      "World Economic Forum => World Economic Forum\n",
      "WEF => World Economic Forum\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\" U.S. President Donald Trump barrels into Davos, Switzerland, on Wednesday, where he is likely to escalate his push for acquiring Greenland despite European protests in the biggest fraying of transatlantic ties in decades.\n",
    "Trump, who marked the end of his turbulent first year in office on Tuesday, is expected to overshadow the annual World Economic Forum (WEF) gathering where global elites discuss economic and political trends in the Swiss mountain resort.\n",
    "\"\"\"\n",
    "labels = ['Donald Trump','Davos','World Economic Forum','European Protests','Switzerland']\n",
    "entities = model.predict_entities(text, labels)\n",
    "\n",
    "for entity in entities:\n",
    "    print(f\"{entity['text']} => {entity['label']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7973a1",
   "metadata": {},
   "source": [
    "# coreference resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe52c3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastcoref\n",
      "  Downloading fastcoref-2.1.6.tar.gz (27 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.64.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from fastcoref) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from fastcoref) (2.3.4)\n",
      "Collecting scipy>=1.7.3 (from fastcoref)\n",
      "  Downloading scipy-1.17.0-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting spacy>=3.0.6 (from fastcoref)\n",
      "  Downloading spacy-3.8.11-cp313-cp313-macosx_11_0_arm64.whl.metadata (27 kB)\n",
      "Requirement already satisfied: torch>=1.10.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from fastcoref) (2.9.1)\n",
      "Requirement already satisfied: transformers>=4.11.3 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from fastcoref) (4.57.6)\n",
      "Collecting datasets>=2.5.2 (from fastcoref)\n",
      "  Downloading datasets-4.5.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.5.2->fastcoref) (3.20.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.5.2->fastcoref) (22.0.0)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets>=2.5.2->fastcoref)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.5.2->fastcoref) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.5.2->fastcoref) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.5.2->fastcoref) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.5.2->fastcoref) (3.6.0)\n",
      "Collecting multiprocess<0.70.19 (from datasets>=2.5.2->fastcoref)\n",
      "  Downloading multiprocess-0.70.18-py313-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.10.0,>=2023.1.0 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.5.2->fastcoref)\n",
      "  Downloading fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.5.2->fastcoref) (0.36.0)\n",
      "Requirement already satisfied: packaging in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.5.2->fastcoref) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.5.2->fastcoref) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.5.2->fastcoref) (3.13.2)\n",
      "Requirement already satisfied: anyio in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets>=2.5.2->fastcoref) (4.11.0)\n",
      "Requirement already satisfied: certifi in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets>=2.5.2->fastcoref) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets>=2.5.2->fastcoref) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets>=2.5.2->fastcoref) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.5.2->fastcoref) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.5.2->fastcoref) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.5.2->fastcoref) (1.2.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.5.2->fastcoref) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.5.2->fastcoref) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.5.2->fastcoref) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.5.2->fastcoref) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.5.2->fastcoref) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.5.2->fastcoref) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.5.2->fastcoref) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from requests>=2.32.2->datasets>=2.5.2->fastcoref) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from requests>=2.32.2->datasets>=2.5.2->fastcoref) (2.5.0)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy>=3.0.6->fastcoref)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy>=3.0.6->fastcoref)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy>=3.0.6->fastcoref)\n",
      "  Downloading murmurhash-1.0.15-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.3 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy>=3.0.6->fastcoref)\n",
      "  Downloading cymem-2.0.13-cp313-cp313-macosx_11_0_arm64.whl.metadata (9.7 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy>=3.0.6->fastcoref)\n",
      "  Downloading preshed-3.0.12-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.5 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy>=3.0.6->fastcoref)\n",
      "  Downloading thinc-8.3.10-cp313-cp313-macosx_11_0_arm64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy>=3.0.6->fastcoref)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy>=3.0.6->fastcoref)\n",
      "  Downloading srsly-2.5.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy>=3.0.6->fastcoref)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.4.2 (from spacy>=3.0.6->fastcoref)\n",
      "  Downloading weasel-0.4.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer-slim<1.0.0,>=0.3.0 (from spacy>=3.0.6->fastcoref)\n",
      "  Using cached typer_slim-0.21.1-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from spacy>=3.0.6->fastcoref) (2.12.3)\n",
      "Requirement already satisfied: jinja2 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from spacy>=3.0.6->fastcoref) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from spacy>=3.0.6->fastcoref) (80.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.6->fastcoref) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.6->fastcoref) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.6->fastcoref) (0.4.2)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy>=3.0.6->fastcoref)\n",
      "  Downloading blis-1.3.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (7.5 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy>=3.0.6->fastcoref)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from typer-slim<1.0.0,>=0.3.0->spacy>=3.0.6->fastcoref) (8.3.0)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.4.2->spacy>=3.0.6->fastcoref)\n",
      "  Downloading cloudpathlib-0.23.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.4.2->spacy>=3.0.6->fastcoref)\n",
      "  Downloading smart_open-7.5.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting wrapt (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy>=3.0.6->fastcoref)\n",
      "  Downloading wrapt-2.0.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from torch>=1.10.0->fastcoref) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from torch>=1.10.0->fastcoref) (3.6.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.10.0->fastcoref) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from transformers>=4.11.3->fastcoref) (2025.10.23)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from transformers>=4.11.3->fastcoref) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from transformers>=4.11.3->fastcoref) (0.7.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from anyio->httpx<1.0.0->datasets>=2.5.2->fastcoref) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from jinja2->spacy>=3.0.6->fastcoref) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from pandas->datasets>=2.5.2->fastcoref) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from pandas->datasets>=2.5.2->fastcoref) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from pandas->datasets>=2.5.2->fastcoref) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.5.2->fastcoref) (1.17.0)\n",
      "Downloading datasets-4.5.0-py3-none-any.whl (515 kB)\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Downloading fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "Downloading multiprocess-0.70.18-py313-none-any.whl (151 kB)\n",
      "Downloading scipy-1.17.0-cp313-cp313-macosx_14_0_arm64.whl (20.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading spacy-3.8.11-cp313-cp313-macosx_11_0_arm64.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.13-cp313-cp313-macosx_11_0_arm64.whl (42 kB)\n",
      "Downloading murmurhash-1.0.15-cp313-cp313-macosx_11_0_arm64.whl (27 kB)\n",
      "Downloading preshed-3.0.12-cp313-cp313-macosx_11_0_arm64.whl (122 kB)\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.2-cp313-cp313-macosx_11_0_arm64.whl (651 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m651.7/651.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading thinc-8.3.10-cp313-cp313-macosx_11_0_arm64.whl (737 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m737.1/737.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading blis-1.3.3-cp313-cp313-macosx_11_0_arm64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading typer_slim-0.21.1-py3-none-any.whl (47 kB)\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.3-py3-none-any.whl (50 kB)\n",
      "Downloading cloudpathlib-0.23.0-py3-none-any.whl (62 kB)\n",
      "Downloading smart_open-7.5.0-py3-none-any.whl (63 kB)\n",
      "Downloading wrapt-2.0.1-cp313-cp313-macosx_11_0_arm64.whl (61 kB)\n",
      "Building wheels for collected packages: fastcoref\n",
      "  Building wheel for fastcoref (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fastcoref: filename=fastcoref-2.1.6-py3-none-any.whl size=31333 sha256=c747ca5006f95c520d5cc6a1ba257b502d2cc7bfd99d73680b0f308987411dc8\n",
      "  Stored in directory: /Users/gurusai/Library/Caches/pip/wheels/28/fa/c6/de27e69bf4a85dd71ad99ff2a8b12d6de77227310794c557aa\n",
      "Successfully built fastcoref\n",
      "Installing collected packages: wrapt, wasabi, typer-slim, spacy-loggers, spacy-legacy, scipy, murmurhash, fsspec, dill, cymem, cloudpathlib, catalogue, blis, srsly, smart-open, preshed, multiprocess, confection, weasel, thinc, datasets, spacy, fastcoref\n",
      "\u001b[2K  Attempting uninstall: fsspec\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/23\u001b[0m [scipy]\n",
      "\u001b[2K    Found existing installation: fsspec 2026.1.0━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/23\u001b[0m [scipy]\n",
      "\u001b[2K    Uninstalling fsspec-2026.1.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/23\u001b[0m [scipy]\n",
      "\u001b[2K      Successfully uninstalled fsspec-2026.1.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/23\u001b[0m [scipy]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/23\u001b[0m [fastcoref]23\u001b[0m [spacy]ts]lib]\n",
      "\u001b[1A\u001b[2KSuccessfully installed blis-1.3.3 catalogue-2.0.10 cloudpathlib-0.23.0 confection-0.1.5 cymem-2.0.13 datasets-4.5.0 dill-0.4.0 fastcoref-2.1.6 fsspec-2025.10.0 multiprocess-0.70.18 murmurhash-1.0.15 preshed-3.0.12 scipy-1.17.0 smart-open-7.5.0 spacy-3.8.11 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.2 thinc-8.3.10 typer-slim-0.21.1 wasabi-1.1.3 weasel-0.4.3 wrapt-2.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install fastcoref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c99ac47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/23/2026 14:19:27 - INFO - \t missing_keys: []\n",
      "01/23/2026 14:19:27 - INFO - \t unexpected_keys: []\n",
      "01/23/2026 14:19:27 - INFO - \t mismatched_keys: []\n",
      "01/23/2026 14:19:27 - INFO - \t error_msgs: []\n",
      "01/23/2026 14:19:27 - INFO - \t Model Parameters: 90.5M, Transformer: 82.1M, Coref head: 8.4M\n",
      "01/23/2026 14:19:27 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 154.99 examples/s]\n",
      "01/23/2026 14:19:27 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 28.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Entity Chain: ['U.S. President Donald Trump', 'he', 'his']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from fastcoref import FCoref\n",
    "\n",
    "# 1. Load the model (optimized for speed)\n",
    "model = FCoref(device='cpu') # Use 'cuda:0' if you have a GPU\n",
    "\n",
    "text = \"U.S. President Donald Trump barrels into Davos, Switzerland, on Wednesday, where he is likely to escalate his push for acquiring Greenland despite European protests in the biggest fraying of transatlantic ties in decades.\"\n",
    "\n",
    "# 2. Predict Clusters\n",
    "preds = model.predict(texts=[text])\n",
    "clusters = preds[0].get_clusters(as_strings=True)\n",
    "\n",
    "# Output: [['U.S. President Donald Trump', 'he', 'his']]\n",
    "print(f\"Detected Entity Chain: {clusters[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d737707",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "LongformerModel does not support an attention implementation through torch.nn.functional.scaled_dot_product_attention yet. Please request the support for this architecture: https://github.com/huggingface/transformers/issues/28005. If you believe this error is a bug, please open an issue in Transformers GitHub repository and load your model with the argument `attn_implementation=\"eager\"` meanwhile. Example: `model = AutoModel.from_pretrained(\"openai/whisper-tiny\", attn_implementation=\"eager\")`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfastcoref\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LingMessCoref\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Load the SOTA model (LingMess) instead of the distilled one\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m model = \u001b[43mLingMessCoref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m text = \u001b[33m\"\"\"\u001b[39m\u001b[33mU.S. President Donald Trump barrels into Davos, Switzerland, on Wednesday, where he is likely to escalate his push for acquiring Greenland despite European protests in the biggest fraying of transatlantic ties in decades.\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[33mTrump, who marked the end of his turbulent first year in office on Tuesday, is expected to overshadow the annual World Economic Forum (WEF) gathering where global elites discuss economic and political trends in the Swiss mountain resort.\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# 2. Predict Clusters\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/fastcoref/modeling.py:285\u001b[39m, in \u001b[36mLingMessCoref.__init__\u001b[39m\u001b[34m(self, model_name_or_path, device, nlp, enable_progress_bar)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_name_or_path=\u001b[33m'\u001b[39m\u001b[33mbiu-nlp/lingmess-coref\u001b[39m\u001b[33m'\u001b[39m, device=\u001b[38;5;28;01mNone\u001b[39;00m, nlp=\u001b[33m\"\u001b[39m\u001b[33men_core_web_sm\u001b[39m\u001b[33m\"\u001b[39m, enable_progress_bar=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLingMessModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPadCollator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable_progress_bar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnlp\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/fastcoref/modeling.py:111\u001b[39m, in \u001b[36mCorefModel.__init__\u001b[39m\u001b[34m(self, model_name_or_path, coref_class, collator_class, enable_progress_bar, device, nlp)\u001b[39m\n\u001b[32m    108\u001b[39m         download(nlp)\n\u001b[32m    109\u001b[39m         \u001b[38;5;28mself\u001b[39m.nlp = spacy.load(nlp, exclude=[\u001b[33m\"\u001b[39m\u001b[33mtagger\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mparser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlemmatizer\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mner\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtextcat\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m \u001b[38;5;28mself\u001b[39m.model, loading_info = \u001b[43mcoref_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_loading_info\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    114\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[38;5;28mself\u001b[39m.model.to(\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m loading_info.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/transformers/modeling_utils.py:277\u001b[39m, in \u001b[36mrestore_default_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    275\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    279\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/transformers/modeling_utils.py:4971\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4968\u001b[39m config = copy.deepcopy(config)  \u001b[38;5;66;03m# We do not want to modify the config inplace in from_pretrained.\u001b[39;00m\n\u001b[32m   4969\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ContextManagers(model_init_context):\n\u001b[32m   4970\u001b[39m     \u001b[38;5;66;03m# Let's make sure we don't run the init function of buffer modules\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4971\u001b[39m     model = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4973\u001b[39m \u001b[38;5;66;03m# Make sure to tie the weights correctly\u001b[39;00m\n\u001b[32m   4974\u001b[39m model.tie_weights()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/fastcoref/coref_models/modeling_lingmess.py:48\u001b[39m, in \u001b[36mLingMessModel.__init__\u001b[39m\u001b[34m(self, config)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28mself\u001b[39m.all_cats_size = \u001b[38;5;28mself\u001b[39m.ffnn_size * \u001b[38;5;28mself\u001b[39m.num_cats\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# this is how huggingface loading the class model and setting the name of the variable.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m base_model = \u001b[43mAutoModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m LingMessModel.base_model_prefix = base_model.base_model_prefix\n\u001b[32m     50\u001b[39m LingMessModel.config_class = base_model.config_class\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/transformers/models/auto/auto_factory.py:456\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_config\u001b[39m\u001b[34m(cls, config, **kwargs)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._model_mapping:\n\u001b[32m    455\u001b[39m     model_class = _get_model_class(config, \u001b[38;5;28mcls\u001b[39m._model_mapping)\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    459\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    460\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    461\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/transformers/modeling_utils.py:277\u001b[39m, in \u001b[36mrestore_default_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    275\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    279\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/transformers/modeling_utils.py:2311\u001b[39m, in \u001b[36mPreTrainedModel._from_config\u001b[39m\u001b[34m(cls, config, **kwargs)\u001b[39m\n\u001b[32m   2308\u001b[39m         model = \u001b[38;5;28mcls\u001b[39m(config, **kwargs)\n\u001b[32m   2310\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2311\u001b[39m     model = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2313\u001b[39m \u001b[38;5;66;03m# restore default dtype if it was modified\u001b[39;00m\n\u001b[32m   2314\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/transformers/models/longformer/modeling_longformer.py:1396\u001b[39m, in \u001b[36mLongformerModel.__init__\u001b[39m\u001b[34m(self, config, add_pooling_layer)\u001b[39m\n\u001b[32m   1391\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config, add_pooling_layer=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m   1392\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1393\u001b[39m \u001b[33;03m    add_pooling_layer (bool, *optional*, defaults to `True`):\u001b[39;00m\n\u001b[32m   1394\u001b[39m \u001b[33;03m        Whether to add a pooling layer\u001b[39;00m\n\u001b[32m   1395\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1396\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1397\u001b[39m     \u001b[38;5;28mself\u001b[39m.config = config\n\u001b[32m   1399\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config.attention_window, \u001b[38;5;28mint\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/transformers/modeling_utils.py:2076\u001b[39m, in \u001b[36mPreTrainedModel.__init__\u001b[39m\u001b[34m(self, config, *inputs, **kwargs)\u001b[39m\n\u001b[32m   2072\u001b[39m \u001b[38;5;28mself\u001b[39m.config = config\n\u001b[32m   2074\u001b[39m \u001b[38;5;66;03m# Check the attention implementation is supported, or set it if not yet set (on the internal attr, to avoid\u001b[39;00m\n\u001b[32m   2075\u001b[39m \u001b[38;5;66;03m# setting it recursively)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2076\u001b[39m \u001b[38;5;28mself\u001b[39m.config._attn_implementation_internal = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_and_adjust_attn_implementation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2077\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_attn_implementation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_init_check\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m   2078\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2080\u001b[39m \u001b[38;5;66;03m# for initialization of the loss\u001b[39;00m\n\u001b[32m   2081\u001b[39m loss_type = \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/transformers/modeling_utils.py:2686\u001b[39m, in \u001b[36mPreTrainedModel._check_and_adjust_attn_implementation\u001b[39m\u001b[34m(self, attn_implementation, is_init_check)\u001b[39m\n\u001b[32m   2684\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   2685\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2686\u001b[39m     applicable_attn_implementation = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_correct_attn_implementation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2687\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapplicable_attn_implementation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_init_check\u001b[49m\n\u001b[32m   2688\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2689\u001b[39m     \u001b[38;5;66;03m# preload flash attention here to allow compile with fullgraph\u001b[39;00m\n\u001b[32m   2690\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m applicable_attn_implementation.startswith(\u001b[33m\"\u001b[39m\u001b[33mflash_attention\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/transformers/modeling_utils.py:2725\u001b[39m, in \u001b[36mPreTrainedModel.get_correct_attn_implementation\u001b[39m\u001b[34m(self, requested_attention, is_init_check)\u001b[39m\n\u001b[32m   2723\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   2724\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m requested_attention == \u001b[33m\"\u001b[39m\u001b[33msdpa\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2725\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   2726\u001b[39m         applicable_attention = \u001b[33m\"\u001b[39m\u001b[33meager\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2728\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m applicable_attention\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/transformers/modeling_utils.py:2722\u001b[39m, in \u001b[36mPreTrainedModel.get_correct_attn_implementation\u001b[39m\u001b[34m(self, requested_attention, is_init_check)\u001b[39m\n\u001b[32m   2719\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m applicable_attention == \u001b[33m\"\u001b[39m\u001b[33msdpa\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2720\u001b[39m     \u001b[38;5;66;03m# Sdpa is the default, so we try it and fallback to eager otherwise when not possible\u001b[39;00m\n\u001b[32m   2721\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2722\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sdpa_can_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_init_check\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2723\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   2724\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m requested_attention == \u001b[33m\"\u001b[39m\u001b[33msdpa\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/transformers/modeling_utils.py:2574\u001b[39m, in \u001b[36mPreTrainedModel._sdpa_can_dispatch\u001b[39m\u001b[34m(self, is_init_check)\u001b[39m\n\u001b[32m   2563\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2564\u001b[39m \u001b[33;03mCheck the availability of SDPA for a given model.\u001b[39;00m\n\u001b[32m   2565\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2571\u001b[39m \u001b[33;03m        before instantiating the full models if we know that the model does not support the requested attention.\u001b[39;00m\n\u001b[32m   2572\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2573\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._supports_sdpa:\n\u001b[32m-> \u001b[39m\u001b[32m2574\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2575\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not support an attention implementation through torch.nn.functional.scaled_dot_product_attention yet.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2576\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m Please request the support for this architecture: https://github.com/huggingface/transformers/issues/28005. If you believe\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2577\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m this error is a bug, please open an issue in Transformers GitHub repository and load your model with the argument `attn_implementation=\u001b[39m\u001b[33m\"\u001b[39m\u001b[33meager\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m` meanwhile. Example: `model = AutoModel.from_pretrained(\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mopenai/whisper-tiny\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m, attn_implementation=\u001b[39m\u001b[33m\"\u001b[39m\u001b[33meager\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m)`\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   2578\u001b[39m     )\n\u001b[32m   2580\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2581\u001b[39m     torch.version.hip \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2582\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m torch.cuda.device_count() > \u001b[32m1\u001b[39m\n\u001b[32m   2583\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m version.parse(torch.__version__) < version.parse(\u001b[33m\"\u001b[39m\u001b[33m2.4.1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2584\u001b[39m ):\n\u001b[32m   2585\u001b[39m     logger.warning_once(\n\u001b[32m   2586\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUsing the `SDPA` attention implementation on multi-gpu setup with ROCM may lead to performance issues due to the FA backend. Disabling it to use alternative backends.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2587\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: LongformerModel does not support an attention implementation through torch.nn.functional.scaled_dot_product_attention yet. Please request the support for this architecture: https://github.com/huggingface/transformers/issues/28005. If you believe this error is a bug, please open an issue in Transformers GitHub repository and load your model with the argument `attn_implementation=\"eager\"` meanwhile. Example: `model = AutoModel.from_pretrained(\"openai/whisper-tiny\", attn_implementation=\"eager\")`"
     ]
    }
   ],
   "source": [
    "from fastcoref import LingMessCoref\n",
    "\n",
    "# Load the SOTA model (LingMess) instead of the distilled one\n",
    "model = LingMessCoref(device='cpu')\n",
    "text = \"\"\"U.S. President Donald Trump barrels into Davos, Switzerland, on Wednesday, where he is likely to escalate his push for acquiring Greenland despite European protests in the biggest fraying of transatlantic ties in decades.\n",
    "Trump, who marked the end of his turbulent first year in office on Tuesday, is expected to overshadow the annual World Economic Forum (WEF) gathering where global elites discuss economic and political trends in the Swiss mountain resort.\n",
    "\"\"\"\n",
    "# 2. Predict Clusters\n",
    "preds = model.predict(texts=[text])\n",
    "clusters = preds[0].get_clusters(as_strings=True)\n",
    "print(f\"Detected Entity Chain: {clusters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59a74e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcoref import LingMessCoref\n",
    "\n",
    "model = LingMessCoref(device='cpu')\n",
    "text = \"\"\"U.S. President Donald Trump barrels into Davos, Switzerland, on Wednesday, where he is likely to escalate his push for acquiring Greenland despite European protests in the biggest fraying of transatlantic ties in decades.\n",
    "Trump, who marked the end of his turbulent first year in office on Tuesday, is expected to overshadow the annual World Economic Forum (WEF) gathering where global elites discuss economic and political trends in the Swiss mountain resort.\n",
    "\"\"\"\n",
    "preds = model.predict(texts=[text])\n",
    "clusters = preds[0].get_clusters(as_strings=True)\n",
    "print(f\"Detected Entity Chain: {clusters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98964cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 54899.27it/s]\n",
      "01/23/2026 14:40:54 - INFO - \t Loading the following GLiNER type: <class 'gliner.model.UniEncoderSpanGLiNER'>...\n",
      "01/23/2026 14:41:01 - INFO - \t missing_keys: []\n",
      "01/23/2026 14:41:01 - INFO - \t unexpected_keys: []\n",
      "01/23/2026 14:41:01 - INFO - \t mismatched_keys: []\n",
      "01/23/2026 14:41:01 - INFO - \t error_msgs: []\n",
      "01/23/2026 14:41:01 - INFO - \t Model Parameters: 90.5M, Transformer: 82.1M, Coref head: 8.4M\n",
      "01/23/2026 14:41:01 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 166.61 examples/s]\n",
      "01/23/2026 14:41:02 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 29.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'start': 15, 'end': 27, 'text': 'Donald Trump', 'label': 'person', 'score': 0.9866982102394104}, {'start': 41, 'end': 46, 'text': 'Davos', 'label': 'place', 'score': 0.9498966932296753}, {'start': 48, 'end': 59, 'text': 'Switzerland', 'label': 'place', 'score': 0.8984706401824951}, {'start': 129, 'end': 138, 'text': 'Greenland', 'label': 'place', 'score': 0.5037164092063904}]\n",
      "[['U.S. President Donald Trump', 'he', 'his']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from fastcoref import FCoref\n",
    "from gliner import GLiNER\n",
    "\n",
    "\n",
    "\n",
    "text = \"U.S. President Donald Trump barrels into Davos, Switzerland, on Wednesday, where he is likely to escalate his push for acquiring Greenland despite European protests in the biggest fraying of transatlantic ties in decades.\"\n",
    "\n",
    "model = GLiNER.from_pretrained(\"urchade/gliner_medium-v2.1\")\n",
    "labels = ['person','place','object']\n",
    "#labels = [\"Person\", \"Business Metric\", \"Strategic Move\"]\n",
    "entities = model.predict_entities(text, labels)\n",
    "# 1. Load the model (optimized for speed)\n",
    "model = FCoref(device='cpu') # Use 'cuda:0' if you have a GPU\n",
    "preds = model.predict(texts=[text])\n",
    "clusters = preds[0].get_clusters(as_strings=True)\n",
    "\n",
    "print(entities)\n",
    "print(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78699ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting setfit\n",
      "  Downloading setfit-1.1.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: datasets>=2.15.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from setfit) (4.5.0)\n",
      "Collecting sentence-transformers>=3 (from sentence-transformers[train]>=3->setfit)\n",
      "  Using cached sentence_transformers-5.2.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: transformers>=4.41.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from setfit) (4.57.6)\n",
      "Collecting evaluate>=0.3.0 (from setfit)\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: huggingface_hub>=0.24.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from setfit) (0.36.0)\n",
      "Collecting scikit-learn (from setfit)\n",
      "  Downloading scikit_learn-1.8.0-cp313-cp313-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from setfit) (24.2)\n",
      "Requirement already satisfied: filelock in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.15.0->setfit) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.15.0->setfit) (2.3.4)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.15.0->setfit) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.15.0->setfit) (0.4.0)\n",
      "Requirement already satisfied: pandas in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.15.0->setfit) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.15.0->setfit) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.15.0->setfit) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.15.0->setfit) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.15.0->setfit) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.15.0->setfit) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.15.0->setfit) (2025.10.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.15.0->setfit) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.15.0->setfit) (3.13.2)\n",
      "Requirement already satisfied: anyio in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets>=2.15.0->setfit) (4.11.0)\n",
      "Requirement already satisfied: certifi in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets>=2.15.0->setfit) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets>=2.15.0->setfit) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets>=2.15.0->setfit) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.15.0->setfit) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from huggingface_hub>=0.24.0->setfit) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from huggingface_hub>=0.24.0->setfit) (1.2.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.15.0->setfit) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.15.0->setfit) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.15.0->setfit) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.15.0->setfit) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.15.0->setfit) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.15.0->setfit) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.15.0->setfit) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from requests>=2.32.2->datasets>=2.15.0->setfit) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from requests>=2.32.2->datasets>=2.15.0->setfit) (2.5.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (2.9.1)\n",
      "Requirement already satisfied: scipy in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (1.17.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from transformers>=4.41.0->setfit) (2025.10.23)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from transformers>=4.41.0->setfit) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from transformers>=4.41.0->setfit) (0.7.0)\n",
      "Collecting accelerate>=0.20.3 (from sentence-transformers[train]>=3->setfit)\n",
      "  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: psutil in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from accelerate>=0.20.3->sentence-transformers[train]>=3->setfit) (7.1.2)\n",
      "Requirement already satisfied: setuptools in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from anyio->httpx<1.0.0->datasets>=2.15.0->setfit) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from pandas->datasets>=2.15.0->setfit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from pandas->datasets>=2.15.0->setfit) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from pandas->datasets>=2.15.0->setfit) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.15.0->setfit) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.3.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from scikit-learn->setfit) (1.5.2)\n",
      "Collecting threadpoolctl>=3.2.0 (from scikit-learn->setfit)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading setfit-1.1.3-py3-none-any.whl (75 kB)\n",
      "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
      "Using cached sentence_transformers-5.2.0-py3-none-any.whl (493 kB)\n",
      "Downloading accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
      "Downloading scikit_learn-1.8.0-cp313-cp313-macosx_12_0_arm64.whl (8.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scikit-learn, accelerate, sentence-transformers, evaluate, setfit\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6/6\u001b[0m [setfit]2m3/6\u001b[0m [sentence-transformers]\n",
      "\u001b[1A\u001b[2KSuccessfully installed accelerate-1.12.0 evaluate-0.4.6 scikit-learn-1.8.0 sentence-transformers-5.2.0 setfit-1.1.3 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install setfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39092e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4/4 [00:00<00:00, 773.25 examples/s]\n",
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
      "/var/folders/v8/1wyl6_ks02s620m7tv5drmch0000gn/T/ipykernel_8736/635375625.py:34: DeprecationWarning: `SetFitTrainer` has been deprecated and will be removed in v2.0.0 of SetFit. Please use `Trainer` instead.\n",
      "  trainer = SetFitTrainer(\n",
      "Map: 100%|██████████| 4/4 [00:00<00:00, 1582.16 examples/s]\n",
      "***** Running training *****\n",
      "  Num unique pairs = 160\n",
      "  Batch size = 16\n",
      "  Num epochs = 1\n",
      "/Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.173300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stance on 'Crypto Ban': Against\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from setfit import SetFitModel, SetFitTrainer\n",
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "\n",
    "# 1. Prepare your data (Simulated output from your GLiNER/Coref pipeline)\n",
    "# Note: You likely have this in a Pandas DataFrame already.\n",
    "data = [\n",
    "    {\"text\": \"Target: Interest Rates | Text: The fed's decision to hike rates is necessary to curb inflation.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Target: Interest Rates | Text: Higher rates are going to strangle the housing market completely.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Target: AI Regulation | Text: We need strict safety guardrails before deploying these models.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Target: AI Regulation | Text: Over-regulation will only stifle innovation in the tech sector.\", \"label\": \"Against\"},\n",
    "    # ... add a few more examples per class ...\n",
    "]\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "dataset = Dataset.from_list(data)\n",
    "\n",
    "# Map labels to integers\n",
    "label_mapping = {\"Against\": 0, \"Neutral\": 1, \"For\": 2}\n",
    "def encode_labels(record):\n",
    "    return {\"label\": label_mapping[record[\"label\"]]}\n",
    "\n",
    "dataset = dataset.map(encode_labels)\n",
    "\n",
    "# 2. Load a Sentence Transformer model\n",
    "# 'paraphrase-mpnet-base-v2' is excellent for semantic understanding, \n",
    "# but for financial/news specific text, you might later try 'sentence-transformers/all-MiniLM-L6-v2' for speed.\n",
    "model = SetFitModel.from_pretrained(\n",
    "    \"sentence-transformers/paraphrase-mpnet-base-v2\",\n",
    "    labels=[\"Against\", \"Neutral\", \"For\"]\n",
    ")\n",
    "\n",
    "# 3. Initialize Trainer\n",
    "trainer = SetFitTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    loss_class=CosineSimilarityLoss, # The magic of SetFit: Contrastive Learning\n",
    "    batch_size=16,\n",
    "    num_iterations=20, # Generates 20 pairs per sentence for contrastive learning\n",
    "    num_epochs=1\n",
    ")\n",
    "\n",
    "# 4. Train\n",
    "trainer.train()\n",
    "\n",
    "# 5. Inference (Simulating your pipeline)\n",
    "target = \"Donald Trump\"\n",
    "sentence = \"U.S. President Donald Trump barrels into Davos, Switzerland, on Wednesday, where he is likely to escalate his push for acquiring Greenland despite European protests in the biggest fraying of transatlantic ties in decades.\"\n",
    "formatted_input = f\"Target: {target} | Text: {sentence}\"\n",
    "\n",
    "preds = model([formatted_input])\n",
    "print(f\"Stance on '{target}': {preds[0]}\")\n",
    "# Output: Stance on 'Crypto Ban': Against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04bef627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stance on 'Donald Trump': For\n"
     ]
    }
   ],
   "source": [
    "# 5. Inference (Simulating your pipeline)\n",
    "target = \"Donald Trump\"\n",
    "sentence = \"U.S. President Donald Trump barrels into Davos, Switzerland, on Wednesday, where he is likely to escalate his push for acquiring Greenland despite European protests in the biggest fraying of transatlantic ties in decades.\"\n",
    "formatted_input = f\"Target: {target} | Text: {sentence}\"\n",
    "\n",
    "preds = model([formatted_input])\n",
    "print(f\"Stance on '{target}': {preds[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbbbb23",
   "metadata": {},
   "source": [
    "# sample article summary:\n",
    "Recovery efforts are underway after Hurricane Melissa left a path of devastation in the Caribbean this week.\n",
    "The United Nations said the damage in Jamaica, where the storm made landfall on Tuesday (October 28) as a Category 5 hurricane, was on a level \"never seen before.\" Cuba is also reported to be calculating cost of damages after homes collapsed and blocked roads, with an estimated 735,000 people reported to be in shelters and the full extent of damage undetermined.\n",
    "At least 31 people have died in relation to Hurricane Melissa's devastation across several countries. At least 25 people died and several remain trapped in homes in Petit-Goáve, Haiti, after a river was flooded by the powerful storm, Mayor Jean Bertrans Subrème told the Associated Press.\n",
    "“I am overwhelmed by the situation,” Subrème said, adding that he’d requested assistance from the government.\n",
    "At least three other deaths, including two caused by a landslide, were also reported in Haiti in relation to Hurricane Melissa, the Haitian Civil Protection Agency confirmed in a statement. At least one person has died in the Dominican Republic, according to officials, who confirmed more than 1,000 others were evacuated or displaced via CNN.\n",
    "Melissa made landfall in Cuba Wednesday (October 29) morning as an \"extremely dangerous\" Category 3, the National Hurricane Center in Miami confirmed via NBC News. The storm previously made landfall in Jamaica on Tuesday as a Category 5 at maximum sustained winds of 185 MPH, which tied with the Labor Day Hurricane of 1935 and Hurricane Dorian in 2019 in the Caribbean and the second-highest wind speed recorded in the Atlantic, behind only Hurricane Allen in 1980.\n",
    "Severe flooding was reported as heavy rains and strong winds hit the province, with more than 750,000 residents had evacuated their homes across the country. The storm was downgraded to Category 4 at 4:00 p.m. ET on Tuesday and a Category 3 early Wednesday morning.\n",
    "Jamaica was reported to have \"suffered major impact\" after the hurricane made landfall, with at least two or three hospitals suffering severe damage and housing expected to be \"severely impacted\" in the storm's path, Prime Minister Andrew Holness said via NBC News.\n",
    "\n",
    "so now, we figure out all the entities in this summary\n",
    "and we need to map the stance on each entity as pos neg or neutral \n",
    "\n",
    "so plan of action is, \n",
    "there's 3 ways of doing this\n",
    "1. sentence by sentence\n",
    "2. paragraph by paragraph\n",
    "3. as an entire passage. \n",
    "\n",
    "we'll go backwards. \n",
    "\n",
    "1. we need to train our SETFIT stance model to completion v1\n",
    "with sufficient models \n",
    "\n",
    "2. pass entire passage\n",
    "\n",
    "3. chunk passage into paragraphs and run it\n",
    "\n",
    "4. chunk each paragraph into sentences and chunk them, \n",
    "\n",
    "5. mix and match?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee164dbb",
   "metadata": {},
   "source": [
    "# Training SETFIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51dd5966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 32/32 [00:00<00:00, 12247.26 examples/s]\n",
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
      "/var/folders/v8/1wyl6_ks02s620m7tv5drmch0000gn/T/ipykernel_72337/1039570162.py:84: DeprecationWarning: `SetFitTrainer` has been deprecated and will be removed in v2.0.0 of SetFit. Please use `Trainer` instead.\n",
      "  trainer = SetFitTrainer(\n",
      "Map: 100%|██████████| 32/32 [00:00<00:00, 5280.63 examples/s]\n",
      "***** Running training *****\n",
      "  Num unique pairs = 1280\n",
      "  Batch size = 16\n",
      "  Num epochs = 2\n",
      "/Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='160' max='160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [160/160 00:46, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.221800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.204400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.022200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.001400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from setfit import SetFitModel, SetFitTrainer\n",
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "\n",
    "# 1. Prepare your data (Simulated output from your GLiNER/Coref pipeline)\n",
    "# Note: You likely haQuestion: ve this in a Pandas DataFrame already.\n",
    "data = [\n",
    "    # --- Finance & Economy ---\n",
    "    {\"text\": \"Question: Is this text expressing support for Interest Rates ? Text: The central bank's decision to hike rates is a necessary evil to curb runaway inflation.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Interest Rates ? Text: These aggressive rate hikes are going to crush the housing market and trigger a recession.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Interest Rates ? Text: The Fed announced a 0.25% increase in the benchmark raQuestion: te this morning.\", \"label\": \"Neutral\"},\n",
    "    \n",
    "    {\"text\": \"Question: Is this text expressing support for Crypto Regulation ? Text: Without strict oversight, the crypto market will remain a haven for scammers and money launderers.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Crypto Regulation ? Text: Heavy-handed government intervention defeats the entire purpose of decentralized finance.\", \"label\": \"Against\"},\n",
    "    \n",
    "    {\"text\": \"Question: Is this text expressing support for Corporate Tax Hike ? Text: Raising taxes on corporations will ensure they pay their fair share towards public infrastructure.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Corporate Tax Hike ? Text: If you increase corporate taxes, companies will just move jobs overseas to cut costs.\", \"label\": \"Against\"},\n",
    "\n",
    "    # --- Tech & AI ---\n",
    "    {\"text\": \"Question: Is this text expressing support for Open Source AI ? Text: democratizing access to powerful models accelerates innovation and transparency.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Open Source AI ? Text: Releasing weights for powerful models is reckless and invites misuse by bad actors.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Open Source AI ? Text: Meta released Llama 3 as an open-weights model yesterday.\", \"label\": \"Neutral\"},\n",
    "\n",
    "    {\"text\": \"Question: Is this text expressing support for Right to Repair ? Text: Consumers should own their devices completely, including the right to fix them without the manufacturer.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Right to Repair ? Text: Allowing unauthorized repairs compromises device security and safety standards.\", \"label\": \"Against\"},\n",
    "\n",
    "    # --- Policy & Society ---\n",
    "    {\"text\": \"Question: Is this text expressing support for Universal Basic Income ? Text: UBI is the only way to support the workforce as automation displaces traditional jobs.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Universal Basic Income ? Text: Handing out free money will disincentivize work and balloon the national debt.\", \"label\": \"Against\"},\n",
    "    \n",
    "    {\"text\": \"Question: Is this text expressing support for Nuclear Energy ? Text: It provides a massive amount of baseload power with zero carbon emissions; we need it.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Nuclear Energy ? Text: The risk of meltdowns and the issue of waste storage make nuclear too dangerous to pursue.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Nuclear Energy ? Text: The new reactor in Georgia has officially connected to the grid.\", \"label\": \"Neutral\"},\n",
    "\n",
    "    {\"text\": \"Question: Is this text expressing support for Rent Control ? Text: Capping rents is essential to keep our cities affordable for the working class.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Rent Control ? Text: Rent control discourages developers from building new housing, which actually makes the shortage worse.\", \"label\": \"Against\"},\n",
    "\n",
    "    # --- Corporate ---\n",
    "    {\"text\": \"Question: Is this text expressing support for Return to Office ? Text: In-person collaboration fosters culture and creativity that Zoom just can't match.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Return to Office ? Text: Forcing employees back to desks is just about control; productivity is higher at home.\", \"label\": \"Against\"},\n",
    "\n",
    "    #extras:\n",
    "    {\"text\": \"Question: Is this text expressing support for Tax Hikes ? Text: Lowering taxes encourages freedom and prosperity.\", \"label\": \"Against\"}, \n",
    "    {\"text\": \"Question: Is this text expressing support for Regulation ? Text: The free market is beautiful and self-correcting without interference.\", \"label\": \"Against\"},\n",
    "    \n",
    "    # Negative words used to support the target\n",
    "    {\"text\": \"Question: Is this text expressing support for Police Reform ? Text: The current corruption is a cancer that destroys trust.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Recall ? Text: The CEO's negligence and toxic behavior ruined the company.\", \"label\": \"For\"},\n",
    "\n",
    "    # but clause nuance\n",
    "    {\"text\": \"Question: Is this text expressing support for EV ? Text: The acceleration is fun, but the range anxiety is a dealbreaker.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for AI ? Text: It makes mistakes, but the speed increase is worth the risk.\", \"label\": \"For\"},\n",
    "\n",
    "    # Negative text -> FOR the solution\n",
    "    {\"text\": \"Question: Is this text expressing support for More Police? Text: The streets are overrun with violent crime and chaos.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Pollution Regulations?Text: My lungs are failing and I can barely breathe due to the smog.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Welfare Increase?Text: We are drowning in debt and can't afford basic groceries. \", \"label\": \"For\"},\n",
    "    \n",
    "    # Positive text -> AGAINST the target (because the status quo is fine)\n",
    "    {\"text\": \"Question: Is this text expressing support for System Overhaul? Text: The current system is working perfectly and everyone is happy. \", \"label\": \"Against\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Martial Law?Text: Our community is safe, peaceful, and thriving as it is.\", \"label\": \"Against\"}\n",
    "\n",
    "]\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "dataset = Dataset.from_list(data)\n",
    "\n",
    "# Map labels to integers\n",
    "label_mapping = {\"Against\": 0, \"Neutral\": 1, \"For\": 2}\n",
    "def encode_labels(record):\n",
    "    return {\"label\": label_mapping[record[\"label\"]]}\n",
    "\n",
    "dataset = dataset.map(encode_labels)\n",
    "\n",
    "# 2. Load a Sentence Transformer model\n",
    "# 'paraphrase-mpnet-base-v2' is excellent for semantic understanding, \n",
    "# but for financial/news specific text, you might later try 'sentence-transformers/all-MiniLM-L6-v2' for speed.\n",
    "model = SetFitModel.from_pretrained(\n",
    "    \"sentence-transformers/paraphrase-mpnet-base-v2\",\n",
    "    labels=[\"Against\", \"Neutral\", \"For\"]\n",
    ")\n",
    "\n",
    "# 3. Initialize Trainer\n",
    "trainer = SetFitTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    loss_class=CosineSimilarityLoss, # The magic of SetFit: Contrastive Learning\n",
    "    batch_size=16,\n",
    "    num_iterations=20, # Generates 20 pairs per sentence for contrastive learning\n",
    "    num_epochs=2\n",
    ")\n",
    "\n",
    "# 4. Train\n",
    "trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307754e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Map: 100%|██████████| 43/43 [00:00<00:00, 5844.87 examples/s]\n",
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
      "/var/folders/v8/1wyl6_ks02s620m7tv5drmch0000gn/T/ipykernel_5662/3095142661.py:108: DeprecationWarning: `SetFitTrainer` has been deprecated and will be removed in v2.0.0 of SetFit. Please use `Trainer` instead.\n",
      "  trainer = SetFitTrainer(\n",
      "Map: 100%|██████████| 43/43 [00:00<00:00, 15647.67 examples/s]\n",
      "***** Running training *****\n",
      "  Num unique pairs = 2580\n",
      "  Batch size = 16\n",
      "  Num epochs = 1\n",
      "/Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training with optimized Gold Set...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='162' max='162' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [162/162 00:41, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.217300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.207100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.023000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.001200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "#### ======== Training with new dataset ========= \n",
    "from datasets import Dataset\n",
    "\n",
    "# Optimized Training Data\n",
    "raw_data = [\n",
    "    # ---------------------------------------------------------\n",
    "    # SECTION 1: STANDARD STANCE (Baseline Logic)\n",
    "    # ---------------------------------------------------------\n",
    "    {\"text\": \"Text: The central bank must raise rates to stop inflation. \\n Question: Is this text expressing support for Rate Hikes?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: Raising rates now will destroy the housing market. \\n Question: Is this text expressing support for Rate Hikes?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: Unions ensure workers get a fair slice of the profits. \\n Question: Is this text expressing support for Unions?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: Unions protect lazy employees and bankrupt companies. \\n Question: Is this text expressing support for Unions?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: Nuclear energy is clean, efficient, and necessary. \\n Question: Is this text expressing support for Nuclear Energy?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: Nuclear waste is a problem we simply cannot solve. \\n Question: Is this text expressing support for Nuclear Energy?\", \"label\": \"Against\"},\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # SECTION 2: THE \"NEWSROOM\" PATCH (Facts != Stance)\n",
    "    # *Crucial for fixing your Neutral errors*\n",
    "    # ---------------------------------------------------------\n",
    "    # Positive facts -> Neutral Stance\n",
    "    {\"text\": \"Text: Bitcoin surged to $70k after the ETF approval. \\n Question: Is this text expressing support for Bitcoin?\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Text: The company reported record profits in Q3. \\n Question: Is this text expressing support for The Company?\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Text: Adoption of EV technology has doubled since 2020. \\n Question: Is this text expressing support for EVs?\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Text: The merger is expected to close by Friday. \\n Question: Is this text expressing support for The Merger?\", \"label\": \"Neutral\"},\n",
    "    \n",
    "    # Negative facts -> Neutral Stance\n",
    "    {\"text\": \"Text: The stock fell 5% due to supply chain issues. \\n Question: Is this text expressing support for The Stock?\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Text: The trial has been delayed for another month. \\n Question: Is this text expressing support for The Trial?\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Text: Inflation ticked up to 3.4% last month. \\n Question: Is this text expressing support for The Economy?\", \"label\": \"Neutral\"},\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # SECTION 3: THE \"IRONIC\" PATCH (Positive Words -> Against)\n",
    "    # *Fixes: \"Ultimate tool for surveillance\"*\n",
    "    # ---------------------------------------------------------\n",
    "    {\"text\": \"Text: A CBDC is the perfect tool for total government surveillance. \\n Question: Is this text expressing support for CBDCs?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: This policy is a fantastic way to destroy small businesses. \\n Question: Is this text expressing support for The Policy?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: It is a highly efficient machine for crushing dissent. \\n Question: Is this text expressing support for The Regime?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: Rug pulls are the most innovative feature of this ecosystem. \\n Question: Is this text expressing support for DeFi?\", \"label\": \"Against\"},\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # SECTION 4: THE \"NECESSARY EVIL\" PATCH (Negative Words -> For)\n",
    "    # *Fixes: \"Painful but necessary\"*\n",
    "    # ---------------------------------------------------------\n",
    "    {\"text\": \"Text: The tax hike hurts, but it's the only way to fix the deficit. \\n Question: Is this text expressing support for Tax Hikes?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: Chemo is poison, but it kills the cancer. \\n Question: Is this text expressing support for Chemo?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: Layoffs are tragic, but necessary to save the company. \\n Question: Is this text expressing support for Layoffs?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: It's an expensive project, but the long-term yield is worth it. \\n Question: Is this text expressing support for The Project?\", \"label\": \"For\"},\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # SECTION 5: \"SUBJECT vs OBJECT\" (Problem vs Solution)\n",
    "    # *Fixes: \"Violent crime\" -> Support for Police*\n",
    "    # ---------------------------------------------------------\n",
    "    {\"text\": \"Text: The streets are overrun with violent criminals. \\n Question: Is this text expressing support for More Police?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: The smog is choking our children. \\n Question: Is this text expressing support for Environmental Regulations?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: The current system is working perfectly for everyone. \\n Question: Is this text expressing support for Radical Reform?\", \"label\": \"Against\"},\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # SECTION 6: DOMAIN SPECIFIC (Finance/Tech/Policy Mix)\n",
    "    # ---------------------------------------------------------\n",
    "    {\"text\": \"Text: Buybacks artificially inflate the stock price while wages stagnate. \\n Question: Is this text expressing support for Buybacks?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: Returning capital to shareholders is a sign of a healthy balance sheet. \\n Question: Is this text expressing support for Buybacks?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: Apple announced a $110B buyback program. \\n Question: Is this text expressing support for Buybacks?\", \"label\": \"Neutral\"},\n",
    "    \n",
    "    {\"text\": \"Text: AI will automate boring tasks and unleash creativity. \\n Question: Is this text expressing support for AI?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: These models are theft machines built on stolen art. \\n Question: Is this text expressing support for AI?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: OpenAI released GPT-4o yesterday. \\n Question: Is this text expressing support for AI?\", \"label\": \"Neutral\"},\n",
    "\n",
    "    {\"text\": \"Text: Fracking secured our energy independence. \\n Question: Is this text expressing support for Fracking?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: Fracking poisons groundwater and causes earthquakes. \\n Question: Is this text expressing support for Fracking?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: Natural gas output hit a new high. \\n Question: Is this text expressing support for Fracking?\", \"label\": \"Neutral\"},\n",
    "\n",
    "    {\"text\": \"Text: Rent control keeps families in their homes. \\n Question: Is this text expressing support for Rent Control?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: Rent control stops developers from building new units. \\n Question: Is this text expressing support for Rent Control?\", \"label\": \"Against\"},\n",
    "\n",
    "    {\"text\": \"Text: Tariffs protect domestic steel jobs. \\n Question: Is this text expressing support for Tariffs?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: Tariffs are just a tax on the consumer. \\n Question: Is this text expressing support for Tariffs?\", \"label\": \"Against\"},\n",
    "    \n",
    "    {\"text\": \"Text: Single-payer is a human right. \\n Question: Is this text expressing support for Single Payer?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: Government healthcare means long wait times. \\n Question: Is this text expressing support for Single Payer?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: The NHS budget was released today. \\n Question: Is this text expressing support for Single Payer?\", \"label\": \"Neutral\"},\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # SECTION 7: TOUGH NUANCE (The \"But\" Clause)\n",
    "    # ---------------------------------------------------------\n",
    "    {\"text\": \"Text: I hate the commute, but the in-person collaboration is unbeatable. \\n Question: Is this text expressing support for Office Work?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: The acceleration is fun, but the charging network is a joke. \\n Question: Is this text expressing support for EVs?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: It lifted millions out of poverty, though the rust belt paid the price. \\n Question: Is this text expressing support for Globalization?\", \"label\": \"Neutral\"}, # Balanced view\n",
    "]\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# EXECUTION CODE\n",
    "# ---------------------------------------------------------\n",
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "from setfit import SetFitModel, Trainer\n",
    "\n",
    "# 1. Prepare Dataset\n",
    "dataset = Dataset.from_list(raw_data)\n",
    "label_mapping = {\"Against\": 0, \"Neutral\": 1, \"For\": 2}\n",
    "dataset = dataset.map(lambda x: {\"label\": label_mapping[x[\"label\"]]})\n",
    "\n",
    "# 2. Load Model\n",
    "model = SetFitModel.from_pretrained(\n",
    "    \"sentence-transformers/paraphrase-mpnet-base-v2\",\n",
    "    labels=[\"Against\", \"Neutral\", \"For\"]\n",
    ")\n",
    "\n",
    "# 3. Train (With slightly higher iterations for the complex data)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    loss_class=CosineSimilarityLoss,\n",
    "    batch_size=16,\n",
    "    num_iterations=30, # Increased from 20 to 30 to learn the edge cases\n",
    "    num_epochs=1\n",
    ")\n",
    "\n",
    "print(\"Starting training with optimized Gold Set...\")\n",
    "trainer.train()\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5822868e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stance on 'Droupadi Murmu': ['Neutral']\n"
     ]
    }
   ],
   "source": [
    "# 5. Inference (Simulating your pipeline)\n",
    "#target = \"Donald Trump\"\n",
    "#sentence = \"U.S. President Donald Trump barrels into Davos, Switzerland, on Wednesday, where he is likely to escalate his push for acquiring Greenland despite European protests in the biggest fraying of transatlantic ties in decades.\"\n",
    "target = \"Droupadi Murmu\"\n",
    "sentence = \"India on Monday celebrated its 77th Republic Day with a grand parade at Kartavya Path, where the national flag was unfurled by the President Droupadi Murmu, with 21 gun salute. The parade showcased the country's military strength, cultural diversity and developmental journey\"\n",
    "formatted_input = f\"Target: {target} | Text: {sentence}\"\n",
    "\n",
    "preds = model([formatted_input])\n",
    "print(f\"Stance on '{target}': {preds}\")\n",
    "# Output: Stance on 'Crypto Ban': Against"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3870f1",
   "metadata": {},
   "source": [
    "# tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3cc134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: Question: Is this text expressing support for Stock Buybacks ? Text: Companies should be investing in R&D and wages, not artificially inflating their stock price.\n",
      "\t label: Against\tpredicted: For\n",
      "text: Question: Is this text expressing support for 5G Towers ? Text: The aesthetic impact and potential health concerns of towers every few blocks are worrying.\n",
      "\t label: Against\tpredicted: For\n",
      "text: Question: Is this text expressing support for Quantum Computing ? Text: Quantum will solve medical/material problems that are impossible for classical computers.\n",
      "\t label: For\tpredicted: Against\n",
      "text: Question: Is this text expressing support for 4-Day Work Week ? Text: Studies show productivity remains high while employee burnout drops significantly.\n",
      "\t label: For\tpredicted: Against\n",
      "text: Question: Is this text expressing support for CEO Pay Caps ? Text: No one works 300 times harder than the average employee; the gap is obscene.\n",
      "\t label: For\tpredicted: Against\n",
      "text: Question: Is this text expressing support for ESG Investing ? Text: Asset managers should focus on returns, not pushing a political agenda.\n",
      "\t label: Against\tpredicted: For\n",
      "text: Question: Is this text expressing support for Interest Rates ? Text: While painful, the rate hikes seem to be cooling the CPI print.\n",
      "\t label: For\tpredicted: Neutral\n",
      "text: Question: Is this text expressing support for AI ? Text: The productivity gains are undeniable, but the job loss risk keeps me up at night.\n",
      "\t label: Neutral\tpredicted: For\n",
      "text: Question: Is this text expressing support for Minimum Wage ? Text: Small businesses are struggling, yet workers can't afford rent.\n",
      "\t label: Neutral\tpredicted: For\n",
      "we have 97 test cases, out of which 88 were guessed correctly, giving an accuracy of 0.9072164948453608%\n"
     ]
    }
   ],
   "source": [
    "test_data = [\n",
    "    # --- FINANCE & CRYPTO ---\n",
    "    {\"text\": \"Question: Is this text expressing support for Bitcoin ? Text: Bitcoin provides financial sovereignty to those in oppressive regimes.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Bitcoin ? Text: The energy consumption of the Bitcoin network is unjustifiable in a climate crisis.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Bitcoin ? Text: Bitcoin is currently trading at $64,000, up 2% from yesterday.\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for CBDCs ? Text: Central Bank Digital Currencies will streamline payments and reduce transaction costs.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for CBDCs ? Text: A CBDC is the ultimate tool for government surveillance of private spending.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for CBDCs ? Text: The Federal Reserve released a white paper exploring the technical feasibility of a digital dollar.\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Stock Buybacks ? Text: Buybacks are a legitimate way to return excess capital to shareholders.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Stock Buybacks ? Text: Companies should be investing in R&D and wages, not artificially inflating their stock price.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Stock Buybacks ? Text: Apple announced a new $90 billion share repurchase program.\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Capital Gains Tax ? Text: Wealth generated from investments should be taxed at the same rate as labor.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Capital Gains Tax ? Text: Raising capital gains taxes will discourage investment and slow economic growth.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Gold Standard ? Text: We need to return to sound money to prevent the government from debasing the currency.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Gold Standard ? Text: Pegging currency to a metal limits the central bank's ability to respond to crises.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Hedge Funds ? Text: Hedge funds provide liquidity and help discover the true price of assets.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Hedge Funds ? Text: These funds are predatory and add no real value to the economy.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for IMF Loans ? Text: IMF support is often the only thing keeping developing nations from total collapse.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for IMF Loans ? Text: The austerity conditions attached to these loans trap nations in debt.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for DeFi ? Text: DeFi removes the middleman, making financial services accessible to the unbanked.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for DeFi ? Text: It's a lawless ecosystem rife with hacks and rug pulls.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for The Euro ? Text: A unified currency strengthens trade ties across the continent.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for The Euro ? Text: A single monetary policy for diverse economies like Germany and Greece is a failure.\", \"label\": \"Against\"},\n",
    "\n",
    "    # --- TECH & AI ---\n",
    "    {\"text\": \"Question: Is this text expressing support for Facial Recognition ? Text: This technology is crucial for catching criminals and finding missing persons quickly.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Facial Recognition ? Text: It is a gross violation of privacy and is often biased against minorities.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Facial Recognition ? Text: The airport is testing biometric scanning at Checkpoint B.\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Social Media Algorithms ? Text: Algorithms help users find content they actually care about among millions of posts.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Social Media Algorithms ? Text: These algorithms are designed to amplify outrage and polarize society.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Social Media Algorithms ? Text: Instagram updated its ranking logic to prioritize original content.\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Self-Driving Cars ? Text: Autonomous vehicles will eventually eliminate human error and save thousands of lives.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Self-Driving Cars ? Text: The technology is not ready and testing it on public roads is dangerous.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Self-Driving Cars ? Text: Waymo has expanded its service area in Phoenix.\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for 5G Towers ? Text: 5G is essential for the next generation of connectivity and smart cities.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for 5G Towers ? Text: The aesthetic impact and potential health concerns of towers every few blocks are worrying.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Data Privacy Laws ? Text: GDPR was a necessary step to give users control over their digital footprint.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Data Privacy Laws ? Text: These compliance costs are crushing small tech startups.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for TikTok Ban ? Text: We cannot allow a foreign adversary to control the information diet of our youth.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for TikTok Ban ? Text: Banning an app because of its origin sets a dangerous precedent for free speech.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for TikTok Ban ? Text: The Senate bill to ban TikTok passed committee yesterday.\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for AI Art ? Text: AI tools democratize creativity, allowing anyone to visualize their ideas.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for AI Art ? Text: It is theft, plain and simple, built on the backs of artists who weren't compensated.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Quantum Computing ? Text: Quantum will solve medical/material problems that are impossible for classical computers.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Quantum Computing ? Text: The threat it poses to current encryption standards is a national security nightmare.\", \"label\": \"Against\"},\n",
    "\n",
    "    # --- POLICY & GOVERNMENT ---\n",
    "    {\"text\": \"Question: Is this text expressing support for Carbon Tax ? Text: Pricing carbon is the most market-efficient way to reduce emissions.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Carbon Tax ? Text: This is just a tax on the poor that will raise the price of gas and heating.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Carbon Tax ? Text: Canada increased its carbon price by $15 per tonne on April 1st.\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Electoral College ? Text: It ensures that smaller states aren't completely ignored by presidential candidates.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Electoral College ? Text: It is undemocratic that a candidate can win the presidency while losing the popular vote.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Affirmative Action ? Text: We need active measures to correct centuries of systemic inequality.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Affirmative Action ? Text: Hiring should be based on merit alone, regardless of background.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Single-Payer Healthcare ? Text: Healthcare is a human right and should not be tied to employment.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Single-Payer Healthcare ? Text: Government-run healthcare leads to long wait times and lower quality of care.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Single-Payer Healthcare ? Text: The UK's NHS budget was released last Tuesday.\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for NATO Expansion ? Text: Expanding the alliance deters aggression and stabilizes Eastern Europe.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for NATO Expansion ? Text: Pushing the alliance borders right up to Russia was an unnecessary provocation.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Gun Control ? Text: Strict background checks are common sense to prevent violence.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Gun Control ? Text: Any infringement on ownership is a violation of the Second Amendment.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for School Vouchers ? Text: Parents should have the choice to use tax dollars for the school that fits their child best.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for School Vouchers ? Text: Vouchers drain critical funding from the public school system.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Death Penalty ? Text: It provides justice for the most heinous crimes.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Death Penalty ? Text: The risk of executing an innocent person is too high to justify it.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Drug Decriminalization ? Text: Treating addiction as a health issue rather than a crime saves lives.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Drug Decriminalization ? Text: This will just encourage more drug use and degrade our city streets.\", \"label\": \"Against\"},\n",
    "\n",
    "    # --- CORPORATE & WORK ---\n",
    "    {\"text\": \"Question: Is this text expressing support for 4-Day Work Week ? Text: Studies show productivity remains high while employee burnout drops significantly.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for 4-Day Work Week ? Text: It is logistically impossible for service industries that need coverage 24/7.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for 4-Day Work Week ? Text: The pilot program in the UK involved 61 companies.\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Unions ? Text: Collective bargaining is the only way workers can get fair wages from massive corporations.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Unions ? Text: Unions protect bad employees and make it impossible to adapt to market changes.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Unions ? Text: Workers at the Buffalo store voted 15-9 to unionize.\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for CEO Pay Caps ? Text: No one works 300 times harder than the average employee; the gap is obscene.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for CEO Pay Caps ? Text: If you cap pay, top talent will just go to other countries.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Gig Economy ? Text: It offers flexibility that traditional 9-to-5 jobs can't match.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Gig Economy ? Text: It's a way for companies to dodge providing benefits and stability.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Non-Compete Agreements ? Text: Companies need to protect their trade secrets when employees leave.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Non-Compete Agreements ? Text: These clauses trap workers and suppress wage growth across the industry.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Non-Compete Agreements ? Text: The FTC proposed a rule to ban non-competes nationwide.\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for ESG Investing ? Text: Considering environmental and social factors is just good long-term risk management.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for ESG Investing ? Text: Asset managers should focus on returns, not pushing a political agenda.\", \"label\": \"Against\"},\n",
    "    \n",
    "    # --- ENERGY & ENVIRONMENT ---\n",
    "    {\"text\": \"Question: Is this text expressing support for EV Subsidies ? Text: We need to bridge the price gap to get people off gas cars.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for EV Subsidies ? Text: Taxpayers shouldn't be subsidizing luxury car purchases for the wealthy.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Fracking ? Text: It made us energy independent and lowered heating costs for everyone.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Fracking ? Text: The risk to groundwater and induced earthquakes is not worth it.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Fracking ? Text: Natural gas production reached a record high last month.\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Plastic Ban ? Text: Single-use plastics are clogging our oceans; we must ban them.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Plastic Ban ? Text: Alternatives like paper straws are functionally worse and often have a higher carbon footprint.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Offshore Wind ? Text: The ocean winds are a massive, untapped source of clean energy.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Offshore Wind ? Text: These massive turbines disrupt marine life and ruin coastal views.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Carbon Capture ? Text: We can't meet climate goals without technology to suck CO2 out of the air.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Carbon Capture ? Text: It's a distraction used by oil companies to delay phasing out fossil fuels.\", \"label\": \"Against\"},\n",
    "\n",
    "    # --- HARD / NUANCED CASES ---\n",
    "    {\"text\": \"Question: Is this text expressing support for Interest Rates ? Text: While painful, the rate hikes seem to be cooling the CPI print.\", \"label\": \"For\"}, \n",
    "    {\"text\": \"Question: Is this text expressing support for Crypto Regulation ? Text: The SEC's approach is creating clarity, even if the industry complains.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for AI ? Text: The productivity gains are undeniable, but the job loss risk keeps me up at night.\", \"label\": \"Neutral\"}, \n",
    "    {\"text\": \"Question: Is this text expressing support for Remote Work ? Text: I miss the office banter, but saving two hours of commute is non-negotiable.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Tariffs ? Text: They might protect steel jobs, but everything at Walmart just got more expensive.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Merger ? Text: Analysts predict the merger will close by Q4 pending regulatory approval.\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Globalization ? Text: It lifted millions out of poverty, though the rust belt paid the price.\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Electric Vehicles ? Text: I love the acceleration, but the charging infrastructure is a joke.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Question: Is this text expressing support for Tax Cuts ? Text: The deficit is exploding, but at least my paycheck is slightly bigger.\", \"label\": \"For\"}, \n",
    "    {\"text\": \"Question: Is this text expressing support for Minimum Wage ? Text: Small businesses are struggling, yet workers can't afford rent.\", \"label\": \"Neutral\"},\n",
    "\n",
    "]\n",
    "correct = 0\n",
    "for i in test_data:\n",
    "    predicted = model([i])\n",
    "    \n",
    "    if predicted[0] == i['label']:\n",
    "        correct+=1\n",
    "    else:\n",
    "        print(f'text: {i['text']}\\n\\t label: {i[\"label\"]}\\tpredicted: {predicted[0]}')\n",
    "\n",
    "print(f\"we have {len(test_data)} test cases, out of which {correct} were guessed correctly, giving an accuracy of {correct/len(test_data)}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826f7fce",
   "metadata": {},
   "source": [
    "##### New Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50710f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "finance_politics_test = [\n",
    "    # --- CENTRAL BANKING & RATES ---\n",
    "    {\"text\": \"Text: The Fed's refusal to pivot is strangling small business growth. \\n Question: Is this text expressing support for High Interest Rates?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: Powell's hawkish stance is the only thing keeping hyperinflation at bay. \\n Question: Is this text expressing support for High Interest Rates?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: The FOMC meeting minutes revealed a split decision on the 25bps hike. \\n Question: Is this text expressing support for High Interest Rates?\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Text: Quantitative tightening is draining necessary liquidity from the bond market. \\n Question: Is this text expressing support for Quantitative Tightening?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: We need to normalize the balance sheet to prevent asset bubbles. \\n Question: Is this text expressing support for Quantitative Tightening?\", \"label\": \"For\"},\n",
    "    \n",
    "    # --- FISCAL POLICY & TAXES ---\n",
    "    {\"text\": \"Text: A wealth tax would finally force billionaires to pay their fair share. \\n Question: Is this text expressing support for Wealth Tax?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: Taxing unrealized gains is unconstitutional and will drive capital offshore. \\n Question: Is this text expressing support for Wealth Tax?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: The Treasury Department released guidance on the new tax brackets today. \\n Question: Is this text expressing support for Wealth Tax?\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Text: Trickle-down economics has failed; we need robust social spending. \\n Question: Is this text expressing support for Supply-Side Economics?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: Cutting corporate taxes fuels investment and job creation. \\n Question: Is this text expressing support for Corporate Tax Cuts?\", \"label\": \"For\"},\n",
    "\n",
    "    # --- MARKETS & INVESTING ---\n",
    "    {\"text\": \"Text: Short sellers are vultures preying on struggling companies. \\n Question: Is this text expressing support for Short Selling?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: Short selling is vital for price discovery and exposing fraud. \\n Question: Is this text expressing support for Short Selling?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: Short interest in the stock rose to 15% this week. \\n Question: Is this text expressing support for Short Selling?\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Text: Passive investing is distorting market signals and reducing competition. \\n Question: Is this text expressing support for Index Funds?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: Low-cost index funds are the best way for average people to build wealth. \\n Question: Is this text expressing support for Index Funds?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: The S&P 500 rebalanced its portfolio to include the new tech giant. \\n Question: Is this text expressing support for Index Funds?\", \"label\": \"Neutral\"},\n",
    "\n",
    "    # --- CRYPTO & FINTECH ---\n",
    "    {\"text\": \"Text: Bitcoin is a Ponzi scheme wrapped in techno-babble. \\n Question: Is this text expressing support for Bitcoin?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: It is the only escape from the debasement of fiat currency. \\n Question: Is this text expressing support for Bitcoin?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: Bitcoin closed at $68,000, down 1.2% on the day. \\n Question: Is this text expressing support for Bitcoin?\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Text: Stablecoins offer the speed of crypto with the stability of the dollar. \\n Question: Is this text expressing support for Stablecoins?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: These unregulated tokens pose a systemic risk to the banking sector. \\n Question: Is this text expressing support for Stablecoins?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: Circle issued a new transparency report for USDC reserves. \\n Question: Is this text expressing support for Stablecoins?\", \"label\": \"Neutral\"},\n",
    "\n",
    "    # --- GEOPOLITICS & TRADE ---\n",
    "    {\"text\": \"Text: Tariffs are necessary to protect our strategic industries from dumping. \\n Question: Is this text expressing support for Tariffs?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: Protectionism always leads to higher prices for consumers and trade wars. \\n Question: Is this text expressing support for Tariffs?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: The trade deficit narrowed by $2 billion in April. \\n Question: Is this text expressing support for Tariffs?\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Text: Leaving the EU gave us back our sovereignty and border control. \\n Question: Is this text expressing support for Brexit?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: Brexit has been an economic disaster for exporters and the City. \\n Question: Is this text expressing support for Brexit?\", \"label\": \"Against\"},\n",
    "    \n",
    "    # --- SOCIAL SAFETY NET ---\n",
    "    {\"text\": \"Text: Social Security is a promise we made to our seniors that must be kept. \\n Question: Is this text expressing support for Social Security?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: It is an insolvent pyramid scheme that bankrupts future generations. \\n Question: Is this text expressing support for Social Security?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: The COLA adjustment for 2024 was announced as 3.2%. \\n Question: Is this text expressing support for Social Security?\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Text: Student loan forgiveness stimulates the economy by freeing young borrowers. \\n Question: Is this text expressing support for Loan Forgiveness?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: It is a slap in the face to everyone who paid off their debts responsibly. \\n Question: Is this text expressing support for Loan Forgiveness?\", \"label\": \"Against\"},\n",
    "\n",
    "    # --- HARD CASES (Irony/Problem-Solution) ---\n",
    "    {\"text\": \"Text: This regulation is a fantastic way to kill innovation overnight. \\n Question: Is this text expressing support for The Regulation?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: The current lack of oversight is a ticking time bomb for investors. \\n Question: Is this text expressing support for Regulation?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: While the subsidy is expensive, the alternative is a collapsed industry. \\n Question: Is this text expressing support for The Subsidy?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: It’s a perfect mechanism for crony capitalism. \\n Question: Is this text expressing support for The Mechanism?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: The bailout prevents a depression, even if it rewards bad behavior. \\n Question: Is this text expressing support for The Bailout?\", \"label\": \"For\"},\n",
    "    # --- HOUSING & REAL ESTATE ---\n",
    "    {\"text\": \"Text: Rent control is the only way to stop displacement in gentrifying neighborhoods. \\n Question: Is this text expressing support for Rent Control?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: Price ceilings on rent discourage maintenance and reduce the quality of housing stock. \\n Question: Is this text expressing support for Rent Control?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: The city council voted 7-2 to freeze rent increases for one year. \\n Question: Is this text expressing support for Rent Control?\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Text: NIMBY zoning laws are artificially restricting supply and spiking prices. \\n Question: Is this text expressing support for Zoning Laws?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: Zoning ensures that industrial waste facilities aren't built next to elementary schools. \\n Question: Is this text expressing support for Zoning Laws?\", \"label\": \"For\"},\n",
    "    \n",
    "    # --- ENERGY POLICY ---\n",
    "    {\"text\": \"Text: Carbon capture is a moral hazard that excuses continued fossil fuel use. \\n Question: Is this text expressing support for Carbon Capture?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: We cannot meet the Paris Agreement targets without industrial-scale carbon removal. \\n Question: Is this text expressing support for Carbon Capture?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: The new facility captures 4,000 tons of CO2 annually. \\n Question: Is this text expressing support for Carbon Capture?\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Text: Subsidizing solar panels is a waste of taxpayer money when nuclear is more reliable. \\n Question: Is this text expressing support for Solar Subsidies?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: Solar credits allow homeowners to achieve energy independence and lower bills. \\n Question: Is this text expressing support for Solar Subsidies?\", \"label\": \"For\"},\n",
    "\n",
    "    # --- LABOR & CORPORATE GOVERNANCE ---\n",
    "    {\"text\": \"Text: The gig economy exploits loopholes to deny workers health insurance. \\n Question: Is this text expressing support for The Gig Economy?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: Uber and DoorDash provide flexibility that a 9-to-5 simply cannot match. \\n Question: Is this text expressing support for The Gig Economy?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: The labor department proposed a new rule regarding independent contractor status. \\n Question: Is this text expressing support for The Gig Economy?\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Text: ESG scores force companies to prioritize politics over profit. \\n Question: Is this text expressing support for ESG?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: Companies with strong ESG ratings historically outperform the market in the long run. \\n Question: Is this text expressing support for ESG?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: BlackRock launched a new sustainable energy ETF today. \\n Question: Is this text expressing support for ESG?\", \"label\": \"Neutral\"},\n",
    "\n",
    "    # --- TRADE & DOLLAR ---\n",
    "    {\"text\": \"Text: A strong dollar hurts our exporters by making American goods expensive abroad. \\n Question: Is this text expressing support for A Strong Dollar?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: A strong dollar keeps import prices low and tames inflation at home. \\n Question: Is this text expressing support for A Strong Dollar?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: The DXY index hit 105.4 this morning. \\n Question: Is this text expressing support for The Dollar?\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Text: Moving supply chains out of China is expensive but necessary for national security. \\n Question: Is this text expressing support for Decoupling?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: Severing ties with China will devastate the global technology sector. \\n Question: Is this text expressing support for Decoupling?\", \"label\": \"Against\"},\n",
    "\n",
    "    # --- CRYPTO & REGULATION (Hard Negatives) ---\n",
    "    {\"text\": \"Text: Privacy coins are essential for human rights in authoritarian regimes. \\n Question: Is this text expressing support for Privacy Coins?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: Monero is primarily used by ransomware gangs and drug traffickers. \\n Question: Is this text expressing support for Monero?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: Tornado Cash was sanctioned by the OFAC yesterday. \\n Question: Is this text expressing support for Tornado Cash?\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Text: Self-custody is the only way to truly own your assets. \\n Question: Is this text expressing support for Self-Custody wallets?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: If you lose your private key, your life savings are gone forever with no recourse. \\n Question: Is this text expressing support for Self-Custody wallets?\", \"label\": \"Against\"},\n",
    "\n",
    "    # --- NUANCE: \"GOOD OUTCOME, BAD METHOD\" ---\n",
    "    {\"text\": \"Text: The acquisition will double our market share, though 500 people will lose their jobs. \\n Question: Is this text expressing support for The Acquisition?\", \"label\": \"For\"}, # Corporate perspective\n",
    "    {\"text\": \"Text: While it saves the company money, outsourcing customer service has ruined our brand reputation. \\n Question: Is this text expressing support for Outsourcing?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: The bailout saved the banks but increased moral hazard for the next crisis. \\n Question: Is this text expressing support for The Bailout?\", \"label\": \"For\"}, # \"Saved\" implies support for the action's primary goal\n",
    "    {\"text\": \"Text: It reduced traffic congestion, but the toll prices are exclusionary for the poor. \\n Question: Is this text expressing support for The Toll Road?\", \"label\": \"Neutral\"}, # Balanced critique\n",
    "\n",
    "    # ... (Add similar variations to reach 100) ...\n",
    "    # (To save space, I've provided ~40 high-density examples here. You can replicate the patterns for other entities like 'Gold', 'IMF', 'Austerity', 'Unions', etc.)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ae19db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: Text: The current lack of oversight is a ticking time bomb for investors. \n",
      " Question: Is this text expressing support for Regulation?\n",
      "\t label: For\tpredicted: Against\n",
      "text: Text: While the subsidy is expensive, the alternative is a collapsed industry. \n",
      " Question: Is this text expressing support for The Subsidy?\n",
      "\t label: For\tpredicted: Against\n",
      "text: Text: Zoning ensures that industrial waste facilities aren't built next to elementary schools. \n",
      " Question: Is this text expressing support for Zoning Laws?\n",
      "\t label: For\tpredicted: Against\n",
      "text: Text: We cannot meet the Paris Agreement targets without industrial-scale carbon removal. \n",
      " Question: Is this text expressing support for Carbon Capture?\n",
      "\t label: For\tpredicted: Against\n",
      "text: Text: Uber and DoorDash provide flexibility that a 9-to-5 simply cannot match. \n",
      " Question: Is this text expressing support for The Gig Economy?\n",
      "\t label: For\tpredicted: Against\n",
      "text: Text: The acquisition will double our market share, though 500 people will lose their jobs. \n",
      " Question: Is this text expressing support for The Acquisition?\n",
      "\t label: For\tpredicted: Neutral\n",
      "text: Text: The bailout saved the banks but increased moral hazard for the next crisis. \n",
      " Question: Is this text expressing support for The Bailout?\n",
      "\t label: For\tpredicted: Against\n",
      "text: Text: It reduced traffic congestion, but the toll prices are exclusionary for the poor. \n",
      " Question: Is this text expressing support for The Toll Road?\n",
      "\t label: Neutral\tpredicted: Against\n",
      "we have 67 test cases, out of which 59 were guessed correctly, giving an accuracy of 0.8805970149253731%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in finance_politics_test:\n",
    "    predicted = model([i])\n",
    "    \n",
    "    if predicted[0] == i['label']:\n",
    "        correct+=1\n",
    "        \n",
    "    else:\n",
    "        print(f'text: {i['text']}\\n\\t label: {i[\"label\"]}\\tpredicted: {predicted[0]}')\n",
    "\n",
    "print(f\"we have {len(finance_politics_test)} test cases, out of which {correct} were guessed correctly, giving an accuracy of {correct/len(finance_politics_test)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b29925d",
   "metadata": {},
   "outputs": [],
   "source": [
    "diverse_reporting_test = [\n",
    "    # --- TECH & AI ---\n",
    "    {\"text\": \"Text: The new VR headset is heavy, nauseating, and overpriced. \\n Question: Is this text expressing support for The Headset?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: It offers an immersion level that simply doesn't exist elsewhere. \\n Question: Is this text expressing support for The Headset?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: The device ships with two controllers and a charging dock. \\n Question: Is this text expressing support for The Headset?\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Text: Open-sourcing the code allows the community to fix bugs faster. \\n Question: Is this text expressing support for Open Source?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: Giving away the proprietary algorithm is business suicide. \\n Question: Is this text expressing support for Open Source?\", \"label\": \"Against\"},\n",
    "\n",
    "    # --- ENVIRONMENT & SCIENCE ---\n",
    "    {\"text\": \"Text: GMOs are the only way to feed a growing global population. \\n Question: Is this text expressing support for GMOs?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: We don't know the long-term health effects of modified crops. \\n Question: Is this text expressing support for GMOs?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: The labeling requirements for bio-engineered foods changed today. \\n Question: Is this text expressing support for GMOs?\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Text: Space exploration drives technological breakthroughs here on Earth. \\n Question: Is this text expressing support for NASA funding?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: We should fix problems on Earth before spending billions on Mars. \\n Question: Is this text expressing support for NASA funding?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: The rover successfully collected a sample from the crater. \\n Question: Is this text expressing support for The Rover?\", \"label\": \"Neutral\"},\n",
    "\n",
    "    # --- LIFESTYLE & WORK ---\n",
    "    {\"text\": \"Text: Remote work destroys company culture and junior mentorship. \\n Question: Is this text expressing support for Remote Work?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: I've never been more productive or healthier since leaving the office. \\n Question: Is this text expressing support for Remote Work?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: 40% of the workforce is now hybrid. \\n Question: Is this text expressing support for Remote Work?\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Text: A vegan diet significantly lowers the risk of heart disease. \\n Question: Is this text expressing support for Veganism?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: It is difficult to get adequate protein and B12 without supplements. \\n Question: Is this text expressing support for Veganism?\", \"label\": \"Against\"},\n",
    "\n",
    "    # --- URBAN PLANNING & TRANSPORT ---\n",
    "    {\"text\": \"Text: High-speed rail would connect our cities and reduce flight emissions. \\n Question: Is this text expressing support for High Speed Rail?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: It's a boondoggle that will cost billions and never be finished. \\n Question: Is this text expressing support for High Speed Rail?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: Construction on the new line begins next Tuesday. \\n Question: Is this text expressing support for High Speed Rail?\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Text: Bike lanes make the streets safer for everyone, including drivers. \\n Question: Is this text expressing support for Bike Lanes?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: They remove critical parking spots and hurt local businesses. \\n Question: Is this text expressing support for Bike Lanes?\", \"label\": \"Against\"},\n",
    "\n",
    "    # --- MEDIA & ENTERTAINMENT ---\n",
    "    {\"text\": \"Text: The sequel lacks the soul and originality of the first movie. \\n Question: Is this text expressing support for The Sequel?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: It is a visual masterpiece that expands the lore beautifully. \\n Question: Is this text expressing support for The Sequel?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: The film grossed $40 million on opening weekend. \\n Question: Is this text expressing support for The Sequel?\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Text: Streaming services offer convenience and massive libraries. \\n Question: Is this text expressing support for Streaming?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: They fragment content so much that you need five subscriptions. \\n Question: Is this text expressing support for Streaming?\", \"label\": \"Against\"},\n",
    "\n",
    "    # --- SPORTS ---\n",
    "    {\"text\": \"Text: VAR ensures fair play and corrects clear errors. \\n Question: Is this text expressing support for VAR (Video Assistant Referee)?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: It ruins the flow of the game and kills the excitement of goals. \\n Question: Is this text expressing support for VAR?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: The referee checked the monitor in the 85th minute. \\n Question: Is this text expressing support for VAR?\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Text: Expanding the tournament dilutes the quality of the matches. \\n Question: Is this text expressing support for Tournament Expansion?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: More teams means more global representation and excitement. \\n Question: Is this text expressing support for Tournament Expansion?\", \"label\": \"For\"},\n",
    "\n",
    "    # --- EDGE CASES (Reporting vs. Stance) ---\n",
    "    {\"text\": \"Text: The study confirmed a correlation between sugar and inflammation. \\n Question: Is this text expressing support for Sugar?\", \"label\": \"Neutral\"}, # Negative fact, but neutral reporting\n",
    "    {\"text\": \"Text: The champion broke the world record by 2 seconds. \\n Question: Is this text expressing support for The Champion?\", \"label\": \"Neutral\"}, # Positive fact, but neutral reporting\n",
    "    {\"text\": \"Text: The festival attracted over 100,000 attendees despite the rain. \\n Question: Is this text expressing support for The Festival?\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Text: While the graphics are dated, the gameplay is timeless. \\n Question: Is this text expressing support for The Game?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: The interface is sleek, but the functionality is broken. \\n Question: Is this text expressing support for The App?\", \"label\": \"Against\"},\n",
    "    # --- EDUCATION ---\n",
    "    {\"text\": \"Text: Standardized testing measures memory, not intelligence. \\n Question: Is this text expressing support for Standardized Testing?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: Tests provide an objective metric to compare student performance across districts. \\n Question: Is this text expressing support for Standardized Testing?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: The SAT will move to a fully digital format next year. \\n Question: Is this text expressing support for The SAT?\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Text: Charter schools drain funding from the public system. \\n Question: Is this text expressing support for Charter Schools?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: Parents deserve a choice if their local public school is failing. \\n Question: Is this text expressing support for Charter Schools?\", \"label\": \"For\"},\n",
    "\n",
    "    # --- HEALTH & DIET ---\n",
    "    {\"text\": \"Text: Keto is unsustainable and puts stress on your kidneys. \\n Question: Is this text expressing support for The Keto Diet?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: I lost 30 pounds and my energy levels have never been higher. \\n Question: Is this text expressing support for The Keto Diet?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: The study tracked 500 participants on a low-carb diet for two years. \\n Question: Is this text expressing support for Low Carb Diets?\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Text: Telehealth allows rural patients to access specialists they otherwise couldn't. \\n Question: Is this text expressing support for Telehealth?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: A doctor cannot properly diagnose you without a physical examination. \\n Question: Is this text expressing support for Telehealth?\", \"label\": \"Against\"},\n",
    "\n",
    "    # --- CONSUMER TECH ---\n",
    "    {\"text\": \"Text: The subscription model forces you to pay forever for software you used to own. \\n Question: Is this text expressing support for Subscriptions?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: Subscriptions ensure the app gets constant updates and security patches. \\n Question: Is this text expressing support for Subscriptions?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: Adobe announced a price increase for the Creative Cloud suite. \\n Question: Is this text expressing support for Adobe?\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Text: Foldable phones are fragile gimmicks that break after a few months. \\n Question: Is this text expressing support for Foldable Phones?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: The multitasking capability on the large screen is a game changer for productivity. \\n Question: Is this text expressing support for Foldable Phones?\", \"label\": \"For\"},\n",
    "\n",
    "    # --- TRANSPORT & INFRASTRUCTURE ---\n",
    "    {\"text\": \"Text: SUVs are safer for the driver but much more dangerous for pedestrians. \\n Question: Is this text expressing support for SUVs?\", \"label\": \"Neutral\"}, # Nuanced\n",
    "    {\"text\": \"Text: They are gas-guzzling monsters that take up too much space. \\n Question: Is this text expressing support for SUVs?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: I need the cargo space for my kids and hockey gear. \\n Question: Is this text expressing support for SUVs?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: Congestion pricing reduces traffic and funds public transit. \\n Question: Is this text expressing support for Congestion Pricing?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: It is a regressive tax on commuters who have no other way to get to work. \\n Question: Is this text expressing support for Congestion Pricing?\", \"label\": \"Against\"},\n",
    "\n",
    "    # --- CULTURE & ETHICS ---\n",
    "    {\"text\": \"Text: Zoos play a critical role in conservation and species survival. \\n Question: Is this text expressing support for Zoos?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: Keeping wild animals in cages for entertainment is cruel. \\n Question: Is this text expressing support for Zoos?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: The San Diego Zoo welcomed a new panda cub today. \\n Question: Is this text expressing support for The Zoo?\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Text: Lab-grown meat is an abomination of nature. \\n Question: Is this text expressing support for Lab-Grown Meat?\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Text: Cultured meat eliminates animal suffering and reduces methane emissions. \\n Question: Is this text expressing support for Lab-Grown Meat?\", \"label\": \"For\"},\n",
    "    {\"text\": \"Text: The FDA approved the sale of lab-grown chicken for the first time. \\n Question: Is this text expressing support for Lab-Grown Meat?\", \"label\": \"Neutral\"},\n",
    "\n",
    "    # --- REPORTING TRAPS (Factual but \"Negative\" Sounding) ---\n",
    "    {\"text\": \"Text: The hurricane caused $50 billion in damages. \\n Question: Is this text expressing support for The Hurricane?\", \"label\": \"Neutral\"}, # Obviously neutral, but tests \"Negative Words = Against\"\n",
    "    {\"text\": \"Text: The virus has mutated into a more contagious strain. \\n Question: Is this text expressing support for The Virus?\", \"label\": \"Neutral\"},\n",
    "    {\"text\": \"Text: The protest blocked the main highway for three hours. \\n Question: Is this text expressing support for The Protest?\", \"label\": \"Neutral\"}, # Reporting on disruption != Opposing it\n",
    "    {\"text\": \"Text: The police arrested 15 demonstrators. \\n Question: Is this text expressing support for The Police?\", \"label\": \"Neutral\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc668bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: Text: It offers an immersion level that simply doesn't exist elsewhere. \n",
      " Question: Is this text expressing support for The Headset?\n",
      "\t label: For\tpredicted: Against\n",
      "text: Text: We should fix problems on Earth before spending billions on Mars. \n",
      " Question: Is this text expressing support for NASA funding?\n",
      "\t label: Against\tpredicted: For\n",
      "text: Text: It is a visual masterpiece that expands the lore beautifully. \n",
      " Question: Is this text expressing support for The Sequel?\n",
      "\t label: For\tpredicted: Neutral\n",
      "text: Text: Streaming services offer convenience and massive libraries. \n",
      " Question: Is this text expressing support for Streaming?\n",
      "\t label: For\tpredicted: Against\n",
      "text: Text: I lost 30 pounds and my energy levels have never been higher. \n",
      " Question: Is this text expressing support for The Keto Diet?\n",
      "\t label: For\tpredicted: Neutral\n",
      "text: Text: SUVs are safer for the driver but much more dangerous for pedestrians. \n",
      " Question: Is this text expressing support for SUVs?\n",
      "\t label: Neutral\tpredicted: Against\n",
      "we have 66 test cases, out of which 60 were guessed correctly, giving an accuracy of 0.9090909090909091%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in diverse_reporting_test:\n",
    "    predicted = model([i])\n",
    "    \n",
    "    if predicted[0] == i['label']:\n",
    "        correct+=1\n",
    "        \n",
    "    else:\n",
    "        print(f'text: {i['text']}\\n\\t label: {i[\"label\"]}\\tpredicted: {predicted[0]}')\n",
    "\n",
    "print(f\"we have {len(diverse_reporting_test)} test cases, out of which {correct} were guessed correctly, giving an accuracy of {correct/len(diverse_reporting_test)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7a5b5296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stance on 'consumers': ['For']\n"
     ]
    }
   ],
   "source": [
    "# 5. Inference (Simulating your pipeline)\n",
    "#target = \"Donald Trump\"\n",
    "#sentence = \"U.S. President Donald Trump barrels into Davos, Switzerland, on Wednesday, where he is likely to escalate his push for acquiring Greenland despite European protests in the biggest fraying of transatlantic ties in decades.\"\n",
    "target = \"consumers\"\n",
    "sentence = \"While China benefits from tariffs, exporters and consumers pay the price.\"\n",
    "formatted_input = f\"Target: {target} | Text: {sentence}\"\n",
    "\n",
    "preds = model([formatted_input])\n",
    "print(f\"Stance on '{target}': {preds}\")\n",
    "# Output: Stance on 'Crypto Ban': Against"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bbc4e9",
   "metadata": {},
   "source": [
    "# Continuous labling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c0c9112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stance on 'Droupadi Murmu': ['Neutral']\n"
     ]
    }
   ],
   "source": [
    "# 5. Inference (Simulating your pipeline)\n",
    "#target = \"Donald Trump\"\n",
    "#sentence = \"U.S. President Donald Trump barrels into Davos, Switzerland, on Wednesday, where he is likely to escalate his push for acquiring Greenland despite European protests in the biggest fraying of transatlantic ties in decades.\"\n",
    "target = \"Droupadi Murmu\"\n",
    "sentence = \"India on Monday celebrated its 77th Republic Day with a grand parade at Kartavya Path, where the national flag was unfurled by the President Droupadi Murmu, with 21 gun salute. The parade showcased the country's military strength, cultural diversity and developmental journey\"\n",
    "formatted_input = f\"Target: {target} | Text: {sentence}\"\n",
    "\n",
    "preds = model([formatted_input])\n",
    "print(f\"Stance on '{target}': {preds}\")\n",
    "# Output: Stance on 'Crypto Ban': Against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28dd51c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "base_model = SetFitModel.from_pretrained(\n",
    "    \"sentence-transformers/paraphrase-mpnet-base-v2\",\n",
    "    labels=[\"Against\", \"Neutral\", \"For\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0ff233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_embeddings = base_model.encode(raw_data)\n",
    "len(initial_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89fcca17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.48722318e-02, -3.27771485e-01, -5.46503859e-03,\n",
       "        -2.94163357e-02, -8.32686608e-04,  1.32332429e-01,\n",
       "        -9.69145447e-02, -9.58879478e-03, -3.35623771e-02,\n",
       "         3.06220800e-01,  8.43247101e-02,  1.49702698e-01,\n",
       "        -2.91545410e-03,  1.26993909e-01, -7.84329176e-02,\n",
       "         7.94866830e-02,  1.44564789e-02,  9.63954031e-02,\n",
       "         2.21635655e-01,  1.49669737e-01,  7.65675977e-02,\n",
       "        -6.29403666e-02,  1.03247605e-01, -5.66904098e-02,\n",
       "        -2.06654258e-02, -1.35567993e-01,  4.92746793e-02,\n",
       "         1.11360168e-02,  9.11053345e-02,  7.62218982e-02,\n",
       "         5.16696349e-02, -3.33824009e-02, -5.92440404e-02,\n",
       "         9.06137154e-02,  3.54576297e-02, -6.60684854e-02,\n",
       "        -5.33176288e-02,  4.31732312e-02, -1.04247332e-01,\n",
       "        -1.70273453e-01,  1.31062478e-01, -2.28295803e-01,\n",
       "         5.50314970e-02, -1.66551080e-02, -2.11136952e-01,\n",
       "         2.86320269e-01,  5.85908629e-02, -4.86917496e-02,\n",
       "         9.16692689e-02,  6.88886344e-02, -5.17360196e-02,\n",
       "         8.65760222e-02, -1.48506641e-01, -3.74312736e-02,\n",
       "        -1.07893102e-01, -7.31272027e-02,  2.78566703e-02,\n",
       "        -5.97602203e-02, -1.88130904e-02,  3.65310371e-01,\n",
       "         6.63861856e-02,  1.03161700e-01,  6.45349100e-02,\n",
       "        -2.33931243e-02, -9.95511860e-02, -1.17663033e-02,\n",
       "        -1.42046988e-01, -6.04004003e-02, -1.26202077e-01,\n",
       "        -4.02745269e-02,  2.97526032e-01,  2.87995003e-02,\n",
       "         6.05037017e-03, -5.29542975e-02, -4.76045609e-02,\n",
       "         1.27921119e-01, -2.21468080e-02, -2.62907714e-01,\n",
       "        -2.18008533e-02,  2.43483856e-02,  1.31242543e-01,\n",
       "        -7.15640336e-02, -8.46879371e-03,  7.53769046e-03,\n",
       "        -1.24931082e-01, -1.29385442e-02, -3.42605524e-02,\n",
       "        -9.31581110e-02,  2.54930984e-02,  4.08978686e-02,\n",
       "        -9.08918902e-02, -9.83382668e-03, -5.10045364e-02,\n",
       "        -5.22459298e-02,  5.42325154e-02,  2.70837545e-02,\n",
       "        -2.25295871e-01, -1.55480951e-01,  1.55040156e-02,\n",
       "        -1.76038593e-01, -4.27509025e-02,  7.02088047e-03,\n",
       "        -6.12192526e-02,  6.07726984e-02,  3.34759392e-02,\n",
       "         5.25027048e-03, -9.94296819e-02,  9.98403784e-03,\n",
       "        -6.81785792e-02,  8.96750391e-02,  1.04433134e-01,\n",
       "        -8.58637542e-02, -3.35342064e-02, -8.90336931e-02,\n",
       "         4.31392267e-02,  1.49970157e-02, -2.24105436e-02,\n",
       "         3.44692096e-02, -7.69182816e-02,  4.56085466e-02,\n",
       "         8.22182000e-03,  6.88038990e-02, -9.41868648e-02,\n",
       "         2.28536921e-03,  8.02541152e-02,  1.76170766e-02,\n",
       "        -8.87664258e-02,  1.33619726e-01,  6.19276892e-03,\n",
       "         1.44908980e-01, -4.40925546e-02, -2.08479129e-02,\n",
       "         8.68720002e-03,  1.31806219e-02,  7.43419603e-02,\n",
       "        -2.46883444e-02,  1.10266462e-01,  3.26497899e-03,\n",
       "         3.45480502e-01,  2.33134553e-02, -1.56794816e-01,\n",
       "        -1.45225143e-02, -9.48532075e-02,  3.86444107e-02,\n",
       "         9.74392146e-02, -3.15910365e-05,  4.09402661e-02,\n",
       "         2.38306418e-01, -6.27977476e-02,  1.12016164e-02,\n",
       "         8.78487378e-02, -1.14301285e-02,  3.89990769e-02,\n",
       "        -1.62736088e-01, -1.62533909e-01, -8.88917074e-02,\n",
       "        -5.40437289e-02, -5.66382781e-02,  5.43246195e-02,\n",
       "         4.28628922e-02, -5.70574077e-03,  8.48986059e-02,\n",
       "        -1.74901947e-01,  5.46947960e-03, -1.40539259e-02,\n",
       "         8.55554044e-02, -3.74745093e-02,  7.46380240e-02,\n",
       "        -8.69828016e-02, -5.67373186e-02, -1.63130672e-03,\n",
       "        -9.01293755e-02, -3.34201381e-02,  1.23798281e-01,\n",
       "        -5.26166894e-02,  2.28487939e-01, -1.13612667e-01,\n",
       "        -3.57944757e-01, -1.05608553e-01,  1.32681280e-01,\n",
       "        -1.63256943e-01,  8.43262300e-02,  1.14360146e-01,\n",
       "         2.94104721e-02, -1.97057500e-01,  3.66276167e-02,\n",
       "         1.09521948e-01, -1.51521459e-01, -8.30942690e-02,\n",
       "         5.48891462e-02, -6.41361624e-02, -1.06457446e-03,\n",
       "        -6.80800676e-02,  2.71361377e-02, -1.38214696e-02,\n",
       "        -8.83421972e-02, -1.34888783e-01, -1.37193948e-01,\n",
       "         9.91215855e-02,  1.95967138e-01,  7.19578797e-03,\n",
       "        -8.49630833e-02,  1.91071704e-02, -1.32747516e-01,\n",
       "        -1.19571604e-01,  3.62259783e-02,  7.42582828e-02,\n",
       "        -3.28581198e-03,  2.20894888e-01,  2.34497070e-01,\n",
       "         2.80163169e-01,  1.79029275e-02, -1.40173927e-01,\n",
       "        -1.08272262e-01,  1.17707662e-01,  2.40884945e-02,\n",
       "         4.97169718e-02, -4.82088374e-03, -1.24669515e-01,\n",
       "         9.06574205e-02, -3.51633504e-02,  1.77383840e-01,\n",
       "        -1.36505470e-01,  5.72642349e-02,  1.32821381e-01,\n",
       "        -1.35527670e-01, -2.63217799e-02,  5.23185171e-02,\n",
       "         8.17429274e-02, -5.31562120e-02, -5.25325630e-03,\n",
       "         5.70892952e-02, -4.24029827e-02,  6.35865629e-02,\n",
       "        -9.63249877e-02,  5.29704541e-02, -2.54979014e-01,\n",
       "        -7.83861950e-02,  8.72649774e-02, -8.61867517e-02,\n",
       "        -3.79583705e-03, -1.47661373e-01, -9.76371765e-02,\n",
       "        -7.31331632e-02,  1.30963743e-01, -1.24027796e-01,\n",
       "        -1.37384851e-02, -1.26324356e-01, -4.94868569e-02,\n",
       "        -4.41128761e-02, -9.12863575e-03,  1.55212387e-01,\n",
       "        -2.37893295e-02,  5.40328585e-02, -4.16192561e-02,\n",
       "         1.03965595e-01,  1.66833982e-01, -1.44220982e-02,\n",
       "         9.65666398e-02,  1.91159934e-01, -7.88165405e-02,\n",
       "         2.62490734e-02, -9.16352961e-03, -2.29103733e-02,\n",
       "         5.39255589e-02,  5.78187741e-02, -7.57114962e-02,\n",
       "         1.09320916e-01, -6.17960840e-02,  1.08946115e-01,\n",
       "         6.51599914e-02, -1.43629201e-02, -1.24204978e-01,\n",
       "        -7.66783673e-03,  1.14203244e-01,  5.88358566e-02,\n",
       "        -8.83722156e-02,  9.15990323e-02, -1.73364460e-01,\n",
       "         2.03154266e-01, -7.94697646e-03,  6.66384920e-02,\n",
       "        -5.36912754e-02, -3.82399745e-02, -1.01854198e-01,\n",
       "        -4.18982878e-02,  2.87466086e-02,  3.58748958e-02,\n",
       "         6.74603730e-02, -1.07137315e-01,  6.51273206e-02,\n",
       "        -4.19635773e-02,  4.12148759e-02, -9.12910998e-02,\n",
       "         1.22048460e-01, -4.79350165e-02,  1.31437480e-01,\n",
       "        -7.27917328e-02, -7.72402361e-02, -7.64566138e-02,\n",
       "        -3.69994305e-02,  6.07315451e-02, -1.69361793e-02,\n",
       "        -5.96648529e-02, -1.54270083e-01,  5.14570251e-02,\n",
       "        -1.19380858e-02,  4.57006618e-02,  1.61811963e-01,\n",
       "         1.80436552e-01,  3.98098379e-02, -2.92195589e-03,\n",
       "         1.03897890e-02,  1.58081368e-01,  2.73171086e-02,\n",
       "         4.41885367e-02, -6.01824522e-02,  1.78408455e-02,\n",
       "        -7.78567269e-02,  1.44633323e-01, -2.12986656e-02,\n",
       "        -1.29293829e-01,  1.17265545e-02, -3.50695625e-02,\n",
       "        -3.97278070e-02, -5.55244125e-02, -7.65368268e-02,\n",
       "        -1.19311847e-01, -1.38548344e-01, -1.48399442e-01,\n",
       "        -3.08394432e-02,  4.31438237e-02,  7.62415156e-02,\n",
       "         1.01743333e-01, -1.21982738e-01, -6.91919178e-02,\n",
       "        -1.59145780e-02,  2.85207061e-03, -1.75828755e-01,\n",
       "         6.27494678e-02, -6.54095458e-03, -1.07357025e-01,\n",
       "         1.70962274e-01, -2.47046098e-01, -7.02293962e-02,\n",
       "         1.32377613e-02,  7.65919164e-02, -6.97507858e-02,\n",
       "         3.01146526e-02,  6.67206664e-03, -9.63488072e-02,\n",
       "        -6.06655627e-02, -2.43468191e-02, -8.85617584e-02,\n",
       "        -3.62458378e-02, -1.64866835e-01,  4.61435392e-02,\n",
       "        -7.13812634e-02, -6.27485290e-02, -1.58261612e-01,\n",
       "        -6.49240315e-02,  3.71916294e-02, -2.47298241e-01,\n",
       "         1.43483341e-01, -2.48539671e-02,  4.37041894e-02,\n",
       "        -2.08219215e-02,  1.26857102e-01, -9.96942371e-02,\n",
       "         2.98967250e-02, -4.02168892e-02,  8.83144587e-02,\n",
       "        -9.70407277e-02, -2.14627422e-02,  3.95063572e-02,\n",
       "         2.33525425e-01,  6.30516484e-02, -3.76613170e-01,\n",
       "         1.43682301e-01, -9.32783261e-02,  9.82862040e-02,\n",
       "        -1.70884982e-01,  1.01287432e-01,  8.89277309e-02,\n",
       "         1.18706338e-02, -1.15075149e-01, -6.69858381e-02,\n",
       "        -1.25256091e-01,  8.14710557e-02,  1.94916978e-01,\n",
       "        -1.07952037e-04, -1.62854508e-01,  7.88231790e-02,\n",
       "        -1.87377930e-01,  9.15482566e-02,  1.94928855e-01,\n",
       "        -5.23549654e-02,  4.68807481e-02,  6.22621849e-02,\n",
       "         1.04589194e-01, -1.07163424e-03,  2.99596321e-02,\n",
       "         8.92738923e-02, -1.26358822e-01,  4.50797640e-02,\n",
       "        -1.13591284e-01,  1.15089126e-01,  1.98267296e-01,\n",
       "         4.84392010e-02,  1.27653524e-01, -2.17713066e-03,\n",
       "        -1.24992222e-01,  1.51342064e-01,  2.37888005e-02,\n",
       "        -1.94541901e-01, -8.79762173e-02, -4.87347580e-02,\n",
       "        -9.53750908e-02, -1.10143572e-02,  6.42701751e-03,\n",
       "         3.64896283e-02,  1.01992495e-01, -5.61940297e-02,\n",
       "        -2.89606955e-02, -4.39033769e-02, -1.07286088e-01,\n",
       "         2.75903076e-01, -1.38705984e-01,  6.13772310e-02,\n",
       "        -1.20264716e-01,  1.54041633e-01, -2.50072517e-02,\n",
       "         5.60286306e-02,  4.91684414e-02, -1.52163520e-01,\n",
       "         7.18247145e-02, -1.61674246e-01,  5.72720729e-02,\n",
       "         3.63523364e-01, -1.44031942e-01, -2.35314178e-03,\n",
       "         1.06096394e-01,  2.31138766e-01, -4.43538614e-02,\n",
       "        -4.90851030e-02,  2.26746082e-01, -6.77074939e-02,\n",
       "         2.85075437e-02, -8.54620412e-02, -2.27047443e-01,\n",
       "        -1.94079895e-02, -2.42162030e-02,  3.38957123e-02,\n",
       "        -1.31987765e-01,  7.03779683e-02,  5.00084162e-02,\n",
       "        -7.42655173e-02, -1.93362206e-01, -1.24593467e-01,\n",
       "        -2.19437614e-01, -1.14124436e-02,  2.16477245e-01,\n",
       "         8.64131097e-03, -2.79007833e-02,  2.32261345e-01,\n",
       "         2.94688009e-02,  1.03356890e-01, -2.85687018e-03,\n",
       "        -1.84242167e-02, -4.77116928e-02, -7.56164342e-02,\n",
       "         4.07017693e-02,  1.28303349e-01,  5.20636402e-02,\n",
       "        -1.48248449e-01, -1.37326390e-01, -2.65402421e-02,\n",
       "        -2.25671440e-01,  2.46447455e-02, -4.68732119e-02,\n",
       "        -5.55083938e-02, -1.82474688e-01, -1.35769797e-02,\n",
       "        -1.72421530e-01, -2.14355029e-02,  8.51111338e-02,\n",
       "        -1.10398717e-01,  3.99484783e-02, -3.82801853e-02,\n",
       "        -1.03007518e-01, -2.52218433e-02, -7.04851076e-02,\n",
       "        -3.63744237e-02,  1.41685143e-01, -1.34123549e-01,\n",
       "         2.65863147e-02,  1.69081062e-01,  2.14895144e-01,\n",
       "        -1.42362453e-02,  2.64829516e-01,  7.61348233e-02,\n",
       "        -9.83281136e-02, -7.40684718e-02, -6.31529614e-02,\n",
       "        -9.35437679e-02,  1.06353633e-01,  3.35416235e-02,\n",
       "        -1.85940117e-02, -1.06741354e-01, -3.51098739e-02,\n",
       "         1.00225478e-01,  1.60157401e-02, -1.69350773e-01,\n",
       "        -1.86571598e-01, -1.33592123e-02, -4.45286483e-02,\n",
       "        -4.23111245e-02, -1.43641397e-01,  1.32635191e-01,\n",
       "        -2.69855130e-02, -1.05657965e-01,  1.32540399e-02,\n",
       "         1.23781219e-01, -7.79740959e-02, -7.80673549e-02,\n",
       "        -8.28862190e-02, -2.59537622e-03,  1.77560262e-02,\n",
       "        -1.20870203e-01, -1.57247819e-02, -1.54053047e-01,\n",
       "         8.34356621e-02, -1.66580215e-01, -2.00274102e-02,\n",
       "        -5.50331064e-02, -5.87652326e-02,  1.49003491e-01,\n",
       "         7.51806647e-02,  1.10333629e-01,  8.63843039e-02,\n",
       "        -4.88312766e-02,  3.99969965e-02,  9.70011279e-02,\n",
       "         5.82167283e-02, -6.39724284e-02,  8.99053365e-02,\n",
       "         5.02332039e-02, -1.81128353e-01, -7.72284716e-02,\n",
       "         9.40728933e-02,  1.32197723e-01,  2.96650864e-02,\n",
       "        -6.86052963e-02,  9.50632095e-02, -6.99055195e-02,\n",
       "        -1.37743670e-02, -3.81169021e-02, -5.79277202e-02,\n",
       "         4.33344692e-02,  8.72413218e-02,  5.77381290e-02,\n",
       "         1.47874698e-01, -1.61346138e-01, -5.80520444e-02,\n",
       "        -6.99027702e-02, -3.79465558e-02, -2.13948395e-02,\n",
       "         3.83950993e-02,  2.28040218e-01, -2.52202023e-02,\n",
       "         4.38035391e-02, -9.96517111e-03,  1.46266907e-01,\n",
       "         7.69976825e-02, -1.31160328e-02, -9.81182605e-02,\n",
       "         9.67362598e-02,  1.55875962e-02,  1.77228928e-01,\n",
       "        -4.59709913e-02,  3.12314689e-01,  1.23222187e-01,\n",
       "        -2.52156761e-02, -2.52973139e-02,  3.92560894e-03,\n",
       "         5.80789847e-03,  7.50612542e-02, -1.23252004e-01,\n",
       "        -3.90820503e-02, -3.11882980e-02, -5.67831248e-02,\n",
       "         3.58006597e-01,  1.82773098e-01, -1.28391594e-01,\n",
       "        -1.88394561e-02,  7.54998773e-02, -1.36820495e-01,\n",
       "         1.08455271e-01,  1.60552323e-01,  1.04233257e-01,\n",
       "        -5.35739474e-02,  8.32565650e-02,  5.36056515e-03,\n",
       "         6.02920614e-02, -8.81630089e-03,  8.84114113e-03,\n",
       "        -1.22832246e-01,  3.56413424e-02, -6.69000484e-03,\n",
       "         1.85545623e-01, -5.09428903e-02,  1.53972492e-01,\n",
       "        -1.04345912e-02, -2.94243135e-02, -4.24151681e-02,\n",
       "        -6.03548475e-02,  5.27555421e-02, -9.96341258e-02,\n",
       "         4.62605953e-02, -9.71495286e-02,  1.46231204e-02,\n",
       "         4.02594730e-02, -1.44101530e-01,  5.68026379e-02,\n",
       "         1.59247935e-01,  6.67645186e-02,  4.81146015e-02,\n",
       "        -2.06357986e-01,  9.95549490e-04,  1.31788984e-01,\n",
       "         1.25437006e-01,  2.54775323e-02, -4.01963182e-02,\n",
       "        -9.39357467e-03,  1.15891881e-01,  2.19795883e-01,\n",
       "         1.12693951e-01, -1.59503445e-02, -2.31787227e-02,\n",
       "        -4.72168364e-02, -1.21931568e-01,  3.39761451e-02,\n",
       "         2.58827247e-02, -4.13761325e-02,  3.72485956e-03,\n",
       "        -4.51361723e-02,  2.55438667e-02,  4.29405496e-02,\n",
       "        -6.39177635e-02,  3.38774733e-02,  8.23752135e-02,\n",
       "         3.83204296e-02, -4.76761274e-02, -6.06083311e-02,\n",
       "        -8.68544728e-02, -7.31406286e-02, -8.19842294e-02,\n",
       "        -1.20459467e-01,  1.91409122e-02, -4.61176783e-02,\n",
       "        -5.56089953e-02,  5.51205799e-02, -4.40615602e-03,\n",
       "        -1.77028179e-01, -7.30304271e-02, -8.45079944e-02,\n",
       "         8.59643221e-02,  1.94429252e-02,  3.75154093e-02,\n",
       "         1.92091558e-02,  7.35590309e-02, -4.91140708e-02,\n",
       "         4.83193770e-02,  1.46426573e-01,  5.59487902e-02,\n",
       "         1.23288650e-02,  4.87191826e-02,  5.42957447e-02,\n",
       "        -1.97508261e-02,  1.38404578e-01, -4.12376076e-02,\n",
       "         4.95037585e-02,  6.12344742e-02,  1.85426205e-01,\n",
       "         4.02535535e-02, -1.86272785e-01, -1.53272431e-02,\n",
       "         4.42940742e-02,  7.02880919e-02,  7.90798292e-02,\n",
       "         1.30110785e-01, -1.23281907e-02,  1.81145892e-02,\n",
       "         9.20052454e-03,  1.68255895e-01, -1.47703156e-01,\n",
       "         1.55175468e-02,  1.43852696e-01,  5.57880029e-02,\n",
       "        -1.73316412e-02, -8.85734931e-02, -2.76680365e-02,\n",
       "        -2.63248645e-02,  4.71316569e-04, -1.96977817e-02,\n",
       "        -2.01892883e-01, -1.05305485e-01,  2.26714425e-02,\n",
       "         8.89408141e-02,  5.22645339e-02, -1.12443738e-01,\n",
       "         1.94727369e-02, -2.61872094e-02, -2.04201519e-01,\n",
       "        -6.56909123e-02,  8.43694210e-02,  3.20279598e-02,\n",
       "         2.56167240e-02, -1.56864636e-02, -1.01227850e-01,\n",
       "        -6.73929090e-03,  1.03505917e-01, -6.68083876e-02,\n",
       "         3.31049711e-02, -6.24731369e-02, -1.02027431e-01,\n",
       "         1.12231486e-01,  3.24853808e-02,  1.88826114e-01,\n",
       "        -3.26284841e-02, -9.53796040e-03,  1.50998272e-02,\n",
       "         3.55842113e-02,  1.32201880e-01, -1.48943886e-01,\n",
       "         7.30807707e-02, -3.26980650e-01, -1.19904704e-01,\n",
       "         9.86265764e-02,  1.14009507e-01, -2.71314755e-02,\n",
       "         1.46815609e-02,  3.28072160e-02,  6.12690188e-02,\n",
       "         9.12026037e-03, -5.98914362e-03,  2.51525082e-02,\n",
       "         9.61934403e-02,  1.33754566e-01,  3.43736000e-02,\n",
       "         2.85593979e-02, -2.96892487e-02,  4.74205375e-01,\n",
       "         5.83846383e-02, -1.53819069e-01, -3.01504415e-02,\n",
       "        -1.00183882e-01,  1.26510769e-01, -3.84126902e-02,\n",
       "         6.91240653e-02,  1.57348663e-01, -6.29556403e-02,\n",
       "         4.79183756e-02, -2.89369319e-02,  1.35521740e-01,\n",
       "         1.45264238e-01, -1.12497605e-01,  1.59555495e-01]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.encode([raw_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e175789b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.48722318e-02, -3.27771485e-01, -5.46503859e-03,\n",
       "        -2.94163357e-02, -8.32686608e-04,  1.32332429e-01,\n",
       "        -9.69145447e-02, -9.58879478e-03, -3.35623771e-02,\n",
       "         3.06220800e-01,  8.43247101e-02,  1.49702698e-01,\n",
       "        -2.91545410e-03,  1.26993909e-01, -7.84329176e-02,\n",
       "         7.94866830e-02,  1.44564789e-02,  9.63954031e-02,\n",
       "         2.21635655e-01,  1.49669737e-01,  7.65675977e-02,\n",
       "        -6.29403666e-02,  1.03247605e-01, -5.66904098e-02,\n",
       "        -2.06654258e-02, -1.35567993e-01,  4.92746793e-02,\n",
       "         1.11360168e-02,  9.11053345e-02,  7.62218982e-02,\n",
       "         5.16696349e-02, -3.33824009e-02, -5.92440404e-02,\n",
       "         9.06137154e-02,  3.54576297e-02, -6.60684854e-02,\n",
       "        -5.33176288e-02,  4.31732312e-02, -1.04247332e-01,\n",
       "        -1.70273453e-01,  1.31062478e-01, -2.28295803e-01,\n",
       "         5.50314970e-02, -1.66551080e-02, -2.11136952e-01,\n",
       "         2.86320269e-01,  5.85908629e-02, -4.86917496e-02,\n",
       "         9.16692689e-02,  6.88886344e-02, -5.17360196e-02,\n",
       "         8.65760222e-02, -1.48506641e-01, -3.74312736e-02,\n",
       "        -1.07893102e-01, -7.31272027e-02,  2.78566703e-02,\n",
       "        -5.97602203e-02, -1.88130904e-02,  3.65310371e-01,\n",
       "         6.63861856e-02,  1.03161700e-01,  6.45349100e-02,\n",
       "        -2.33931243e-02, -9.95511860e-02, -1.17663033e-02,\n",
       "        -1.42046988e-01, -6.04004003e-02, -1.26202077e-01,\n",
       "        -4.02745269e-02,  2.97526032e-01,  2.87995003e-02,\n",
       "         6.05037017e-03, -5.29542975e-02, -4.76045609e-02,\n",
       "         1.27921119e-01, -2.21468080e-02, -2.62907714e-01,\n",
       "        -2.18008533e-02,  2.43483856e-02,  1.31242543e-01,\n",
       "        -7.15640336e-02, -8.46879371e-03,  7.53769046e-03,\n",
       "        -1.24931082e-01, -1.29385442e-02, -3.42605524e-02,\n",
       "        -9.31581110e-02,  2.54930984e-02,  4.08978686e-02,\n",
       "        -9.08918902e-02, -9.83382668e-03, -5.10045364e-02,\n",
       "        -5.22459298e-02,  5.42325154e-02,  2.70837545e-02,\n",
       "        -2.25295871e-01, -1.55480951e-01,  1.55040156e-02,\n",
       "        -1.76038593e-01, -4.27509025e-02,  7.02088047e-03,\n",
       "        -6.12192526e-02,  6.07726984e-02,  3.34759392e-02,\n",
       "         5.25027048e-03, -9.94296819e-02,  9.98403784e-03,\n",
       "        -6.81785792e-02,  8.96750391e-02,  1.04433134e-01,\n",
       "        -8.58637542e-02, -3.35342064e-02, -8.90336931e-02,\n",
       "         4.31392267e-02,  1.49970157e-02, -2.24105436e-02,\n",
       "         3.44692096e-02, -7.69182816e-02,  4.56085466e-02,\n",
       "         8.22182000e-03,  6.88038990e-02, -9.41868648e-02,\n",
       "         2.28536921e-03,  8.02541152e-02,  1.76170766e-02,\n",
       "        -8.87664258e-02,  1.33619726e-01,  6.19276892e-03,\n",
       "         1.44908980e-01, -4.40925546e-02, -2.08479129e-02,\n",
       "         8.68720002e-03,  1.31806219e-02,  7.43419603e-02,\n",
       "        -2.46883444e-02,  1.10266462e-01,  3.26497899e-03,\n",
       "         3.45480502e-01,  2.33134553e-02, -1.56794816e-01,\n",
       "        -1.45225143e-02, -9.48532075e-02,  3.86444107e-02,\n",
       "         9.74392146e-02, -3.15910365e-05,  4.09402661e-02,\n",
       "         2.38306418e-01, -6.27977476e-02,  1.12016164e-02,\n",
       "         8.78487378e-02, -1.14301285e-02,  3.89990769e-02,\n",
       "        -1.62736088e-01, -1.62533909e-01, -8.88917074e-02,\n",
       "        -5.40437289e-02, -5.66382781e-02,  5.43246195e-02,\n",
       "         4.28628922e-02, -5.70574077e-03,  8.48986059e-02,\n",
       "        -1.74901947e-01,  5.46947960e-03, -1.40539259e-02,\n",
       "         8.55554044e-02, -3.74745093e-02,  7.46380240e-02,\n",
       "        -8.69828016e-02, -5.67373186e-02, -1.63130672e-03,\n",
       "        -9.01293755e-02, -3.34201381e-02,  1.23798281e-01,\n",
       "        -5.26166894e-02,  2.28487939e-01, -1.13612667e-01,\n",
       "        -3.57944757e-01, -1.05608553e-01,  1.32681280e-01,\n",
       "        -1.63256943e-01,  8.43262300e-02,  1.14360146e-01,\n",
       "         2.94104721e-02, -1.97057500e-01,  3.66276167e-02,\n",
       "         1.09521948e-01, -1.51521459e-01, -8.30942690e-02,\n",
       "         5.48891462e-02, -6.41361624e-02, -1.06457446e-03,\n",
       "        -6.80800676e-02,  2.71361377e-02, -1.38214696e-02,\n",
       "        -8.83421972e-02, -1.34888783e-01, -1.37193948e-01,\n",
       "         9.91215855e-02,  1.95967138e-01,  7.19578797e-03,\n",
       "        -8.49630833e-02,  1.91071704e-02, -1.32747516e-01,\n",
       "        -1.19571604e-01,  3.62259783e-02,  7.42582828e-02,\n",
       "        -3.28581198e-03,  2.20894888e-01,  2.34497070e-01,\n",
       "         2.80163169e-01,  1.79029275e-02, -1.40173927e-01,\n",
       "        -1.08272262e-01,  1.17707662e-01,  2.40884945e-02,\n",
       "         4.97169718e-02, -4.82088374e-03, -1.24669515e-01,\n",
       "         9.06574205e-02, -3.51633504e-02,  1.77383840e-01,\n",
       "        -1.36505470e-01,  5.72642349e-02,  1.32821381e-01,\n",
       "        -1.35527670e-01, -2.63217799e-02,  5.23185171e-02,\n",
       "         8.17429274e-02, -5.31562120e-02, -5.25325630e-03,\n",
       "         5.70892952e-02, -4.24029827e-02,  6.35865629e-02,\n",
       "        -9.63249877e-02,  5.29704541e-02, -2.54979014e-01,\n",
       "        -7.83861950e-02,  8.72649774e-02, -8.61867517e-02,\n",
       "        -3.79583705e-03, -1.47661373e-01, -9.76371765e-02,\n",
       "        -7.31331632e-02,  1.30963743e-01, -1.24027796e-01,\n",
       "        -1.37384851e-02, -1.26324356e-01, -4.94868569e-02,\n",
       "        -4.41128761e-02, -9.12863575e-03,  1.55212387e-01,\n",
       "        -2.37893295e-02,  5.40328585e-02, -4.16192561e-02,\n",
       "         1.03965595e-01,  1.66833982e-01, -1.44220982e-02,\n",
       "         9.65666398e-02,  1.91159934e-01, -7.88165405e-02,\n",
       "         2.62490734e-02, -9.16352961e-03, -2.29103733e-02,\n",
       "         5.39255589e-02,  5.78187741e-02, -7.57114962e-02,\n",
       "         1.09320916e-01, -6.17960840e-02,  1.08946115e-01,\n",
       "         6.51599914e-02, -1.43629201e-02, -1.24204978e-01,\n",
       "        -7.66783673e-03,  1.14203244e-01,  5.88358566e-02,\n",
       "        -8.83722156e-02,  9.15990323e-02, -1.73364460e-01,\n",
       "         2.03154266e-01, -7.94697646e-03,  6.66384920e-02,\n",
       "        -5.36912754e-02, -3.82399745e-02, -1.01854198e-01,\n",
       "        -4.18982878e-02,  2.87466086e-02,  3.58748958e-02,\n",
       "         6.74603730e-02, -1.07137315e-01,  6.51273206e-02,\n",
       "        -4.19635773e-02,  4.12148759e-02, -9.12910998e-02,\n",
       "         1.22048460e-01, -4.79350165e-02,  1.31437480e-01,\n",
       "        -7.27917328e-02, -7.72402361e-02, -7.64566138e-02,\n",
       "        -3.69994305e-02,  6.07315451e-02, -1.69361793e-02,\n",
       "        -5.96648529e-02, -1.54270083e-01,  5.14570251e-02,\n",
       "        -1.19380858e-02,  4.57006618e-02,  1.61811963e-01,\n",
       "         1.80436552e-01,  3.98098379e-02, -2.92195589e-03,\n",
       "         1.03897890e-02,  1.58081368e-01,  2.73171086e-02,\n",
       "         4.41885367e-02, -6.01824522e-02,  1.78408455e-02,\n",
       "        -7.78567269e-02,  1.44633323e-01, -2.12986656e-02,\n",
       "        -1.29293829e-01,  1.17265545e-02, -3.50695625e-02,\n",
       "        -3.97278070e-02, -5.55244125e-02, -7.65368268e-02,\n",
       "        -1.19311847e-01, -1.38548344e-01, -1.48399442e-01,\n",
       "        -3.08394432e-02,  4.31438237e-02,  7.62415156e-02,\n",
       "         1.01743333e-01, -1.21982738e-01, -6.91919178e-02,\n",
       "        -1.59145780e-02,  2.85207061e-03, -1.75828755e-01,\n",
       "         6.27494678e-02, -6.54095458e-03, -1.07357025e-01,\n",
       "         1.70962274e-01, -2.47046098e-01, -7.02293962e-02,\n",
       "         1.32377613e-02,  7.65919164e-02, -6.97507858e-02,\n",
       "         3.01146526e-02,  6.67206664e-03, -9.63488072e-02,\n",
       "        -6.06655627e-02, -2.43468191e-02, -8.85617584e-02,\n",
       "        -3.62458378e-02, -1.64866835e-01,  4.61435392e-02,\n",
       "        -7.13812634e-02, -6.27485290e-02, -1.58261612e-01,\n",
       "        -6.49240315e-02,  3.71916294e-02, -2.47298241e-01,\n",
       "         1.43483341e-01, -2.48539671e-02,  4.37041894e-02,\n",
       "        -2.08219215e-02,  1.26857102e-01, -9.96942371e-02,\n",
       "         2.98967250e-02, -4.02168892e-02,  8.83144587e-02,\n",
       "        -9.70407277e-02, -2.14627422e-02,  3.95063572e-02,\n",
       "         2.33525425e-01,  6.30516484e-02, -3.76613170e-01,\n",
       "         1.43682301e-01, -9.32783261e-02,  9.82862040e-02,\n",
       "        -1.70884982e-01,  1.01287432e-01,  8.89277309e-02,\n",
       "         1.18706338e-02, -1.15075149e-01, -6.69858381e-02,\n",
       "        -1.25256091e-01,  8.14710557e-02,  1.94916978e-01,\n",
       "        -1.07952037e-04, -1.62854508e-01,  7.88231790e-02,\n",
       "        -1.87377930e-01,  9.15482566e-02,  1.94928855e-01,\n",
       "        -5.23549654e-02,  4.68807481e-02,  6.22621849e-02,\n",
       "         1.04589194e-01, -1.07163424e-03,  2.99596321e-02,\n",
       "         8.92738923e-02, -1.26358822e-01,  4.50797640e-02,\n",
       "        -1.13591284e-01,  1.15089126e-01,  1.98267296e-01,\n",
       "         4.84392010e-02,  1.27653524e-01, -2.17713066e-03,\n",
       "        -1.24992222e-01,  1.51342064e-01,  2.37888005e-02,\n",
       "        -1.94541901e-01, -8.79762173e-02, -4.87347580e-02,\n",
       "        -9.53750908e-02, -1.10143572e-02,  6.42701751e-03,\n",
       "         3.64896283e-02,  1.01992495e-01, -5.61940297e-02,\n",
       "        -2.89606955e-02, -4.39033769e-02, -1.07286088e-01,\n",
       "         2.75903076e-01, -1.38705984e-01,  6.13772310e-02,\n",
       "        -1.20264716e-01,  1.54041633e-01, -2.50072517e-02,\n",
       "         5.60286306e-02,  4.91684414e-02, -1.52163520e-01,\n",
       "         7.18247145e-02, -1.61674246e-01,  5.72720729e-02,\n",
       "         3.63523364e-01, -1.44031942e-01, -2.35314178e-03,\n",
       "         1.06096394e-01,  2.31138766e-01, -4.43538614e-02,\n",
       "        -4.90851030e-02,  2.26746082e-01, -6.77074939e-02,\n",
       "         2.85075437e-02, -8.54620412e-02, -2.27047443e-01,\n",
       "        -1.94079895e-02, -2.42162030e-02,  3.38957123e-02,\n",
       "        -1.31987765e-01,  7.03779683e-02,  5.00084162e-02,\n",
       "        -7.42655173e-02, -1.93362206e-01, -1.24593467e-01,\n",
       "        -2.19437614e-01, -1.14124436e-02,  2.16477245e-01,\n",
       "         8.64131097e-03, -2.79007833e-02,  2.32261345e-01,\n",
       "         2.94688009e-02,  1.03356890e-01, -2.85687018e-03,\n",
       "        -1.84242167e-02, -4.77116928e-02, -7.56164342e-02,\n",
       "         4.07017693e-02,  1.28303349e-01,  5.20636402e-02,\n",
       "        -1.48248449e-01, -1.37326390e-01, -2.65402421e-02,\n",
       "        -2.25671440e-01,  2.46447455e-02, -4.68732119e-02,\n",
       "        -5.55083938e-02, -1.82474688e-01, -1.35769797e-02,\n",
       "        -1.72421530e-01, -2.14355029e-02,  8.51111338e-02,\n",
       "        -1.10398717e-01,  3.99484783e-02, -3.82801853e-02,\n",
       "        -1.03007518e-01, -2.52218433e-02, -7.04851076e-02,\n",
       "        -3.63744237e-02,  1.41685143e-01, -1.34123549e-01,\n",
       "         2.65863147e-02,  1.69081062e-01,  2.14895144e-01,\n",
       "        -1.42362453e-02,  2.64829516e-01,  7.61348233e-02,\n",
       "        -9.83281136e-02, -7.40684718e-02, -6.31529614e-02,\n",
       "        -9.35437679e-02,  1.06353633e-01,  3.35416235e-02,\n",
       "        -1.85940117e-02, -1.06741354e-01, -3.51098739e-02,\n",
       "         1.00225478e-01,  1.60157401e-02, -1.69350773e-01,\n",
       "        -1.86571598e-01, -1.33592123e-02, -4.45286483e-02,\n",
       "        -4.23111245e-02, -1.43641397e-01,  1.32635191e-01,\n",
       "        -2.69855130e-02, -1.05657965e-01,  1.32540399e-02,\n",
       "         1.23781219e-01, -7.79740959e-02, -7.80673549e-02,\n",
       "        -8.28862190e-02, -2.59537622e-03,  1.77560262e-02,\n",
       "        -1.20870203e-01, -1.57247819e-02, -1.54053047e-01,\n",
       "         8.34356621e-02, -1.66580215e-01, -2.00274102e-02,\n",
       "        -5.50331064e-02, -5.87652326e-02,  1.49003491e-01,\n",
       "         7.51806647e-02,  1.10333629e-01,  8.63843039e-02,\n",
       "        -4.88312766e-02,  3.99969965e-02,  9.70011279e-02,\n",
       "         5.82167283e-02, -6.39724284e-02,  8.99053365e-02,\n",
       "         5.02332039e-02, -1.81128353e-01, -7.72284716e-02,\n",
       "         9.40728933e-02,  1.32197723e-01,  2.96650864e-02,\n",
       "        -6.86052963e-02,  9.50632095e-02, -6.99055195e-02,\n",
       "        -1.37743670e-02, -3.81169021e-02, -5.79277202e-02,\n",
       "         4.33344692e-02,  8.72413218e-02,  5.77381290e-02,\n",
       "         1.47874698e-01, -1.61346138e-01, -5.80520444e-02,\n",
       "        -6.99027702e-02, -3.79465558e-02, -2.13948395e-02,\n",
       "         3.83950993e-02,  2.28040218e-01, -2.52202023e-02,\n",
       "         4.38035391e-02, -9.96517111e-03,  1.46266907e-01,\n",
       "         7.69976825e-02, -1.31160328e-02, -9.81182605e-02,\n",
       "         9.67362598e-02,  1.55875962e-02,  1.77228928e-01,\n",
       "        -4.59709913e-02,  3.12314689e-01,  1.23222187e-01,\n",
       "        -2.52156761e-02, -2.52973139e-02,  3.92560894e-03,\n",
       "         5.80789847e-03,  7.50612542e-02, -1.23252004e-01,\n",
       "        -3.90820503e-02, -3.11882980e-02, -5.67831248e-02,\n",
       "         3.58006597e-01,  1.82773098e-01, -1.28391594e-01,\n",
       "        -1.88394561e-02,  7.54998773e-02, -1.36820495e-01,\n",
       "         1.08455271e-01,  1.60552323e-01,  1.04233257e-01,\n",
       "        -5.35739474e-02,  8.32565650e-02,  5.36056515e-03,\n",
       "         6.02920614e-02, -8.81630089e-03,  8.84114113e-03,\n",
       "        -1.22832246e-01,  3.56413424e-02, -6.69000484e-03,\n",
       "         1.85545623e-01, -5.09428903e-02,  1.53972492e-01,\n",
       "        -1.04345912e-02, -2.94243135e-02, -4.24151681e-02,\n",
       "        -6.03548475e-02,  5.27555421e-02, -9.96341258e-02,\n",
       "         4.62605953e-02, -9.71495286e-02,  1.46231204e-02,\n",
       "         4.02594730e-02, -1.44101530e-01,  5.68026379e-02,\n",
       "         1.59247935e-01,  6.67645186e-02,  4.81146015e-02,\n",
       "        -2.06357986e-01,  9.95549490e-04,  1.31788984e-01,\n",
       "         1.25437006e-01,  2.54775323e-02, -4.01963182e-02,\n",
       "        -9.39357467e-03,  1.15891881e-01,  2.19795883e-01,\n",
       "         1.12693951e-01, -1.59503445e-02, -2.31787227e-02,\n",
       "        -4.72168364e-02, -1.21931568e-01,  3.39761451e-02,\n",
       "         2.58827247e-02, -4.13761325e-02,  3.72485956e-03,\n",
       "        -4.51361723e-02,  2.55438667e-02,  4.29405496e-02,\n",
       "        -6.39177635e-02,  3.38774733e-02,  8.23752135e-02,\n",
       "         3.83204296e-02, -4.76761274e-02, -6.06083311e-02,\n",
       "        -8.68544728e-02, -7.31406286e-02, -8.19842294e-02,\n",
       "        -1.20459467e-01,  1.91409122e-02, -4.61176783e-02,\n",
       "        -5.56089953e-02,  5.51205799e-02, -4.40615602e-03,\n",
       "        -1.77028179e-01, -7.30304271e-02, -8.45079944e-02,\n",
       "         8.59643221e-02,  1.94429252e-02,  3.75154093e-02,\n",
       "         1.92091558e-02,  7.35590309e-02, -4.91140708e-02,\n",
       "         4.83193770e-02,  1.46426573e-01,  5.59487902e-02,\n",
       "         1.23288650e-02,  4.87191826e-02,  5.42957447e-02,\n",
       "        -1.97508261e-02,  1.38404578e-01, -4.12376076e-02,\n",
       "         4.95037585e-02,  6.12344742e-02,  1.85426205e-01,\n",
       "         4.02535535e-02, -1.86272785e-01, -1.53272431e-02,\n",
       "         4.42940742e-02,  7.02880919e-02,  7.90798292e-02,\n",
       "         1.30110785e-01, -1.23281907e-02,  1.81145892e-02,\n",
       "         9.20052454e-03,  1.68255895e-01, -1.47703156e-01,\n",
       "         1.55175468e-02,  1.43852696e-01,  5.57880029e-02,\n",
       "        -1.73316412e-02, -8.85734931e-02, -2.76680365e-02,\n",
       "        -2.63248645e-02,  4.71316569e-04, -1.96977817e-02,\n",
       "        -2.01892883e-01, -1.05305485e-01,  2.26714425e-02,\n",
       "         8.89408141e-02,  5.22645339e-02, -1.12443738e-01,\n",
       "         1.94727369e-02, -2.61872094e-02, -2.04201519e-01,\n",
       "        -6.56909123e-02,  8.43694210e-02,  3.20279598e-02,\n",
       "         2.56167240e-02, -1.56864636e-02, -1.01227850e-01,\n",
       "        -6.73929090e-03,  1.03505917e-01, -6.68083876e-02,\n",
       "         3.31049711e-02, -6.24731369e-02, -1.02027431e-01,\n",
       "         1.12231486e-01,  3.24853808e-02,  1.88826114e-01,\n",
       "        -3.26284841e-02, -9.53796040e-03,  1.50998272e-02,\n",
       "         3.55842113e-02,  1.32201880e-01, -1.48943886e-01,\n",
       "         7.30807707e-02, -3.26980650e-01, -1.19904704e-01,\n",
       "         9.86265764e-02,  1.14009507e-01, -2.71314755e-02,\n",
       "         1.46815609e-02,  3.28072160e-02,  6.12690188e-02,\n",
       "         9.12026037e-03, -5.98914362e-03,  2.51525082e-02,\n",
       "         9.61934403e-02,  1.33754566e-01,  3.43736000e-02,\n",
       "         2.85593979e-02, -2.96892487e-02,  4.74205375e-01,\n",
       "         5.83846383e-02, -1.53819069e-01, -3.01504415e-02,\n",
       "        -1.00183882e-01,  1.26510769e-01, -3.84126902e-02,\n",
       "         6.91240653e-02,  1.57348663e-01, -6.29556403e-02,\n",
       "         4.79183756e-02, -2.89369319e-02,  1.35521740e-01,\n",
       "         1.45264238e-01, -1.12497605e-01,  1.59555495e-01]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.encode([raw_data[0]['text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707e89af",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_training_embeddings = model.model_body.encode(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "553098f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e40423",
   "metadata": {},
   "source": [
    "# TODO: compute similarity and visualise it changing the embedding/latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "deab11b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(initial_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c73950f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "reducer = umap.UMAP(\n",
    "    n_neighbors=15,\n",
    "    min_dist=0.1,\n",
    "    metric=\"cosine\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_base_2d   = reducer.fit_transform(initial_embeddings)\n",
    "X_setfit_2d = reducer.fit_transform(post_training_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bf8c36cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [x['label'] for x in raw_data]\n",
    "y = [-1 if x =='Against' else 0 if x =='Neutral' else 1 for x in y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c0bd2acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "0",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "1",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "y",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "8515bc08-a0ac-4a19-a6d2-05a696580cb0",
       "rows": [
        [
         "0",
         "9.267161",
         "-1.9242408",
         "1"
        ],
        [
         "1",
         "-9.285642",
         "16.694548",
         "-1"
        ],
        [
         "2",
         "9.6126",
         "-1.1854762",
         "1"
        ],
        [
         "3",
         "-9.489463",
         "17.060432",
         "-1"
        ],
        [
         "4",
         "10.019955",
         "-1.7383386",
         "1"
        ],
        [
         "5",
         "-9.254588",
         "16.457289",
         "-1"
        ],
        [
         "6",
         "-2.8049216",
         "-4.823909",
         "0"
        ],
        [
         "7",
         "-2.8008525",
         "-5.286259",
         "0"
        ],
        [
         "8",
         "-3.1568599",
         "-5.3154693",
         "0"
        ],
        [
         "9",
         "-2.4751577",
         "-5.501783",
         "0"
        ],
        [
         "10",
         "-2.2785192",
         "-4.485142",
         "0"
        ],
        [
         "11",
         "-2.2508626",
         "-4.7811146",
         "0"
        ],
        [
         "12",
         "-2.5957367",
         "-4.4443717",
         "0"
        ],
        [
         "13",
         "-9.818787",
         "16.123842",
         "-1"
        ],
        [
         "14",
         "-9.748914",
         "16.60601",
         "-1"
        ],
        [
         "15",
         "-9.798075",
         "16.857416",
         "-1"
        ],
        [
         "16",
         "-9.605312",
         "16.273876",
         "-1"
        ],
        [
         "17",
         "9.047477",
         "-2.2648344",
         "1"
        ],
        [
         "18",
         "9.482795",
         "-2.813256",
         "1"
        ],
        [
         "19",
         "8.90838",
         "-2.110161",
         "1"
        ],
        [
         "20",
         "9.065353",
         "-2.4881916",
         "1"
        ],
        [
         "21",
         "9.646356",
         "-2.0807474",
         "1"
        ],
        [
         "22",
         "10.077946",
         "-2.3001647",
         "1"
        ],
        [
         "23",
         "-9.498741",
         "15.72478",
         "-1"
        ],
        [
         "24",
         "-8.841963",
         "16.546328",
         "-1"
        ],
        [
         "25",
         "9.438054",
         "-1.3431927",
         "1"
        ],
        [
         "26",
         "-3.0062187",
         "-4.6872506",
         "0"
        ],
        [
         "27",
         "9.711774",
         "-1.6926435",
         "1"
        ],
        [
         "28",
         "-9.0266",
         "17.186613",
         "-1"
        ],
        [
         "29",
         "-2.503833",
         "-5.001891",
         "0"
        ],
        [
         "30",
         "10.161523",
         "-1.4132546",
         "1"
        ],
        [
         "31",
         "-9.134156",
         "17.267355",
         "-1"
        ],
        [
         "32",
         "-2.9174755",
         "-5.169809",
         "0"
        ],
        [
         "33",
         "9.154384",
         "-1.4669484",
         "1"
        ],
        [
         "34",
         "-8.836167",
         "16.315517",
         "-1"
        ],
        [
         "35",
         "9.738256",
         "-1.095773",
         "1"
        ],
        [
         "36",
         "-8.551704",
         "17.253323",
         "-1"
        ],
        [
         "37",
         "10.315859",
         "-1.9728616",
         "1"
        ],
        [
         "38",
         "-9.156912",
         "15.964485",
         "-1"
        ],
        [
         "39",
         "-2.1350334",
         "-5.26425",
         "0"
        ],
        [
         "40",
         "9.720869",
         "-2.583139",
         "1"
        ],
        [
         "41",
         "-8.648566",
         "16.875776",
         "-1"
        ],
        [
         "42",
         "-2.869593",
         "-5.7432547",
         "0"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 43
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.267161</td>\n",
       "      <td>-1.924241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9.285642</td>\n",
       "      <td>16.694548</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.612600</td>\n",
       "      <td>-1.185476</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9.489463</td>\n",
       "      <td>17.060432</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.019955</td>\n",
       "      <td>-1.738339</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-9.254588</td>\n",
       "      <td>16.457289</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-2.804922</td>\n",
       "      <td>-4.823909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-2.800853</td>\n",
       "      <td>-5.286259</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-3.156860</td>\n",
       "      <td>-5.315469</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-2.475158</td>\n",
       "      <td>-5.501783</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-2.278519</td>\n",
       "      <td>-4.485142</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-2.250863</td>\n",
       "      <td>-4.781115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-2.595737</td>\n",
       "      <td>-4.444372</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-9.818787</td>\n",
       "      <td>16.123842</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-9.748914</td>\n",
       "      <td>16.606010</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-9.798075</td>\n",
       "      <td>16.857416</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-9.605312</td>\n",
       "      <td>16.273876</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9.047477</td>\n",
       "      <td>-2.264834</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9.482795</td>\n",
       "      <td>-2.813256</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8.908380</td>\n",
       "      <td>-2.110161</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9.065353</td>\n",
       "      <td>-2.488192</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9.646356</td>\n",
       "      <td>-2.080747</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10.077946</td>\n",
       "      <td>-2.300165</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-9.498741</td>\n",
       "      <td>15.724780</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-8.841963</td>\n",
       "      <td>16.546328</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9.438054</td>\n",
       "      <td>-1.343193</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-3.006219</td>\n",
       "      <td>-4.687251</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9.711774</td>\n",
       "      <td>-1.692644</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-9.026600</td>\n",
       "      <td>17.186613</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-2.503833</td>\n",
       "      <td>-5.001891</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>10.161523</td>\n",
       "      <td>-1.413255</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-9.134156</td>\n",
       "      <td>17.267355</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-2.917475</td>\n",
       "      <td>-5.169809</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>9.154384</td>\n",
       "      <td>-1.466948</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-8.836167</td>\n",
       "      <td>16.315517</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>9.738256</td>\n",
       "      <td>-1.095773</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-8.551704</td>\n",
       "      <td>17.253323</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>10.315859</td>\n",
       "      <td>-1.972862</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-9.156912</td>\n",
       "      <td>15.964485</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-2.135033</td>\n",
       "      <td>-5.264250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>9.720869</td>\n",
       "      <td>-2.583139</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-8.648566</td>\n",
       "      <td>16.875776</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-2.869593</td>\n",
       "      <td>-5.743255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1  y\n",
       "0    9.267161  -1.924241  1\n",
       "1   -9.285642  16.694548 -1\n",
       "2    9.612600  -1.185476  1\n",
       "3   -9.489463  17.060432 -1\n",
       "4   10.019955  -1.738339  1\n",
       "5   -9.254588  16.457289 -1\n",
       "6   -2.804922  -4.823909  0\n",
       "7   -2.800853  -5.286259  0\n",
       "8   -3.156860  -5.315469  0\n",
       "9   -2.475158  -5.501783  0\n",
       "10  -2.278519  -4.485142  0\n",
       "11  -2.250863  -4.781115  0\n",
       "12  -2.595737  -4.444372  0\n",
       "13  -9.818787  16.123842 -1\n",
       "14  -9.748914  16.606010 -1\n",
       "15  -9.798075  16.857416 -1\n",
       "16  -9.605312  16.273876 -1\n",
       "17   9.047477  -2.264834  1\n",
       "18   9.482795  -2.813256  1\n",
       "19   8.908380  -2.110161  1\n",
       "20   9.065353  -2.488192  1\n",
       "21   9.646356  -2.080747  1\n",
       "22  10.077946  -2.300165  1\n",
       "23  -9.498741  15.724780 -1\n",
       "24  -8.841963  16.546328 -1\n",
       "25   9.438054  -1.343193  1\n",
       "26  -3.006219  -4.687251  0\n",
       "27   9.711774  -1.692644  1\n",
       "28  -9.026600  17.186613 -1\n",
       "29  -2.503833  -5.001891  0\n",
       "30  10.161523  -1.413255  1\n",
       "31  -9.134156  17.267355 -1\n",
       "32  -2.917475  -5.169809  0\n",
       "33   9.154384  -1.466948  1\n",
       "34  -8.836167  16.315517 -1\n",
       "35   9.738256  -1.095773  1\n",
       "36  -8.551704  17.253323 -1\n",
       "37  10.315859  -1.972862  1\n",
       "38  -9.156912  15.964485 -1\n",
       "39  -2.135033  -5.264250  0\n",
       "40   9.720869  -2.583139  1\n",
       "41  -8.648566  16.875776 -1\n",
       "42  -2.869593  -5.743255  0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pre_training = pd.DataFrame(X_base_2d)\n",
    "pre_training['y'] = y\n",
    "\n",
    "post_training = pd.DataFrame(X_setfit_2d)\n",
    "post_training['y'] = y\n",
    "post_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "782c7e69",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m fig, axes = plt.subplots(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, figsize=(\u001b[32m12\u001b[39m, \u001b[32m5\u001b[39m))\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m label, color \u001b[38;5;129;01min\u001b[39;00m [(-\u001b[32m1\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mred\u001b[39m\u001b[33m\"\u001b[39m), (\u001b[32m0\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mgray\u001b[39m\u001b[33m\"\u001b[39m), (\u001b[32m1\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mgreen\u001b[39m\u001b[33m\"\u001b[39m)]:\n\u001b[32m      4\u001b[39m     axes[\u001b[32m0\u001b[39m].scatter(\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m         X_base_2d[\u001b[43my\u001b[49m == label, \u001b[32m0\u001b[39m],\n\u001b[32m      6\u001b[39m         X_base_2d[y == label, \u001b[32m1\u001b[39m],\n\u001b[32m      7\u001b[39m         c=color, label=\u001b[38;5;28mstr\u001b[39m(label), alpha=\u001b[32m0.6\u001b[39m\n\u001b[32m      8\u001b[39m     )\n\u001b[32m      9\u001b[39m     axes[\u001b[32m1\u001b[39m].scatter(\n\u001b[32m     10\u001b[39m         X_setfit_2d[y == label, \u001b[32m0\u001b[39m],\n\u001b[32m     11\u001b[39m         X_setfit_2d[y == label, \u001b[32m1\u001b[39m],\n\u001b[32m     12\u001b[39m         c=color, label=\u001b[38;5;28mstr\u001b[39m(label), alpha=\u001b[32m0.6\u001b[39m\n\u001b[32m     13\u001b[39m     )\n\u001b[32m     15\u001b[39m axes[\u001b[32m0\u001b[39m].set_title(\u001b[33m\"\u001b[39m\u001b[33mBefore SetFit\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'y' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "for label, color in [(-1, \"red\"), (0, \"gray\"), (1, \"green\")]:\n",
    "    axes[0].scatter(\n",
    "        X_base_2d[y == label, 0],\n",
    "        X_base_2d[y == label, 1],\n",
    "        c=color, label=str(label), alpha=0.6\n",
    "    )\n",
    "    axes[1].scatter(\n",
    "        X_setfit_2d[y == label, 0],\n",
    "        X_setfit_2d[y == label, 1],\n",
    "        c=color, label=str(label), alpha=0.6\n",
    "    )\n",
    "\n",
    "axes[0].set_title(\"Before SetFit\")\n",
    "axes[1].set_title(\"After SetFit\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6ff5ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
