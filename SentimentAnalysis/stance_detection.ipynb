{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04ddd131",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Fetching 5 files: 100%|██████████| 5/5 [02:06<00:00, 25.40s/it]\n",
      "/Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/transformers/convert_slow_tokenizer.py:566: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Musk => Person\n",
      "analysts => Person\n",
      "margin compression => Business Metric\n",
      "demand => Business Metric\n"
     ]
    }
   ],
   "source": [
    "from gliner import GLiNER\n",
    "\n",
    "model = GLiNER.from_pretrained(\"urchade/gliner_medium-v2.1\")\n",
    "\n",
    "text = \"While Musk pushes for rapid expansion, analysts worry about margin compression and demand.\"\n",
    "\n",
    "# Define CUSTOM labels on the fly\n",
    "labels = [\"Person\", \"Business Metric\", \"Strategic Move\"]\n",
    "\n",
    "entities = model.predict_entities(text, labels)\n",
    "\n",
    "for entity in entities:\n",
    "    print(f\"{entity['text']} => {entity['label']}\")\n",
    "\n",
    "# Output:\n",
    "# Musk => Person\n",
    "# rapid expansion => Strategic Move\n",
    "# margin compression => Business Metric\n",
    "# demand => Business Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df5314b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Air Force One => object\n",
      "Joint Base Andrews => place\n",
      "Maryland => place\n",
      "Press Secretary Karoline Leavitt => person\n",
      "Trump => person\n",
      "Trump => person\n",
      "World Economic Forum => place\n",
      "Trump => person\n"
     ]
    }
   ],
   "source": [
    "new_text = \"\"\"Air Force One returned to Joint Base Andrews, an air base in Maryland, out of an abundance of caution, Press Secretary Karoline Leavitt said. It landed shortly after 11 pm (local time), after about an hour and 20 minutes in the air.\n",
    "Journalists travelling with Trump reported that the lights in the cabin went out briefly after takeoff, as per the news agency AFP.\n",
    "Trump and his entourage resumed their trip to the World Economic Forum after switching to another plane. Trump took off two-and-a-half hours after his initial departure. He is scheduled to arrive on Wednesday and leave on Thursday.\"\"\"\n",
    "labels = ['person','place','object','']\n",
    "#labels = [\"Person\", \"Business Metric\", \"Strategic Move\"]\n",
    "entities = model.predict_entities(new_text, labels)\n",
    "\n",
    "for entity in entities:\n",
    "    print(f\"{entity['text']} => {entity['label']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49eda62e",
   "metadata": {},
   "source": [
    " This is interesting, different labels are leading it to classify differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1056edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donald Trump => person\n",
      "Davos => place\n",
      "Switzerland => place\n",
      "Wednesday => time\n",
      "Greenland => place\n",
      "European protests => political event\n",
      "Tuesday => time\n",
      "World Economic Forum => meeting\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\" U.S. President Donald Trump barrels into Davos, Switzerland, on Wednesday, where he is likely to escalate his push for acquiring Greenland despite European protests in the biggest fraying of transatlantic ties in decades.\n",
    "Trump, who marked the end of his turbulent first year in office on Tuesday, is expected to overshadow the annual World Economic Forum (WEF) gathering where global elites discuss economic and political trends in the Swiss mountain resort.\n",
    "\"\"\"\n",
    "labels = ['person','place','object','time','political event','meeting']\n",
    "#labels = [\"Person\", \"Business Metric\", \"Strategic Move\"]\n",
    "entities = model.predict_entities(text, labels)\n",
    "\n",
    "for entity in entities:\n",
    "    print(f\"{entity['text']} => {entity['label']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13b6d82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donald Trump => Donald Trump\n",
      "Davos => Davos\n",
      "Switzerland => Switzerland\n",
      "European protests => European Protests\n",
      "World Economic Forum => World Economic Forum\n",
      "WEF => World Economic Forum\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\" U.S. President Donald Trump barrels into Davos, Switzerland, on Wednesday, where he is likely to escalate his push for acquiring Greenland despite European protests in the biggest fraying of transatlantic ties in decades.\n",
    "Trump, who marked the end of his turbulent first year in office on Tuesday, is expected to overshadow the annual World Economic Forum (WEF) gathering where global elites discuss economic and political trends in the Swiss mountain resort.\n",
    "\"\"\"\n",
    "labels = ['Donald Trump','Davos','World Economic Forum','European Protests','Switzerland']\n",
    "entities = model.predict_entities(text, labels)\n",
    "\n",
    "for entity in entities:\n",
    "    print(f\"{entity['text']} => {entity['label']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7973a1",
   "metadata": {},
   "source": [
    "# coreference resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe52c3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastcoref\n",
      "  Downloading fastcoref-2.1.6.tar.gz (27 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.64.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from fastcoref) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from fastcoref) (2.3.4)\n",
      "Collecting scipy>=1.7.3 (from fastcoref)\n",
      "  Downloading scipy-1.17.0-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting spacy>=3.0.6 (from fastcoref)\n",
      "  Downloading spacy-3.8.11-cp313-cp313-macosx_11_0_arm64.whl.metadata (27 kB)\n",
      "Requirement already satisfied: torch>=1.10.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from fastcoref) (2.9.1)\n",
      "Requirement already satisfied: transformers>=4.11.3 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from fastcoref) (4.57.6)\n",
      "Collecting datasets>=2.5.2 (from fastcoref)\n",
      "  Downloading datasets-4.5.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.5.2->fastcoref) (3.20.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.5.2->fastcoref) (22.0.0)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets>=2.5.2->fastcoref)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.5.2->fastcoref) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.5.2->fastcoref) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.5.2->fastcoref) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.5.2->fastcoref) (3.6.0)\n",
      "Collecting multiprocess<0.70.19 (from datasets>=2.5.2->fastcoref)\n",
      "  Downloading multiprocess-0.70.18-py313-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.10.0,>=2023.1.0 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.5.2->fastcoref)\n",
      "  Downloading fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.5.2->fastcoref) (0.36.0)\n",
      "Requirement already satisfied: packaging in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.5.2->fastcoref) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.5.2->fastcoref) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.5.2->fastcoref) (3.13.2)\n",
      "Requirement already satisfied: anyio in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets>=2.5.2->fastcoref) (4.11.0)\n",
      "Requirement already satisfied: certifi in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets>=2.5.2->fastcoref) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets>=2.5.2->fastcoref) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets>=2.5.2->fastcoref) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.5.2->fastcoref) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.5.2->fastcoref) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.5.2->fastcoref) (1.2.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.5.2->fastcoref) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.5.2->fastcoref) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.5.2->fastcoref) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.5.2->fastcoref) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.5.2->fastcoref) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.5.2->fastcoref) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.5.2->fastcoref) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from requests>=2.32.2->datasets>=2.5.2->fastcoref) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from requests>=2.32.2->datasets>=2.5.2->fastcoref) (2.5.0)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy>=3.0.6->fastcoref)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy>=3.0.6->fastcoref)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy>=3.0.6->fastcoref)\n",
      "  Downloading murmurhash-1.0.15-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.3 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy>=3.0.6->fastcoref)\n",
      "  Downloading cymem-2.0.13-cp313-cp313-macosx_11_0_arm64.whl.metadata (9.7 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy>=3.0.6->fastcoref)\n",
      "  Downloading preshed-3.0.12-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.5 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy>=3.0.6->fastcoref)\n",
      "  Downloading thinc-8.3.10-cp313-cp313-macosx_11_0_arm64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy>=3.0.6->fastcoref)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy>=3.0.6->fastcoref)\n",
      "  Downloading srsly-2.5.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy>=3.0.6->fastcoref)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.4.2 (from spacy>=3.0.6->fastcoref)\n",
      "  Downloading weasel-0.4.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer-slim<1.0.0,>=0.3.0 (from spacy>=3.0.6->fastcoref)\n",
      "  Using cached typer_slim-0.21.1-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from spacy>=3.0.6->fastcoref) (2.12.3)\n",
      "Requirement already satisfied: jinja2 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from spacy>=3.0.6->fastcoref) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from spacy>=3.0.6->fastcoref) (80.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.6->fastcoref) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.6->fastcoref) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.6->fastcoref) (0.4.2)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy>=3.0.6->fastcoref)\n",
      "  Downloading blis-1.3.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (7.5 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy>=3.0.6->fastcoref)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from typer-slim<1.0.0,>=0.3.0->spacy>=3.0.6->fastcoref) (8.3.0)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.4.2->spacy>=3.0.6->fastcoref)\n",
      "  Downloading cloudpathlib-0.23.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.4.2->spacy>=3.0.6->fastcoref)\n",
      "  Downloading smart_open-7.5.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting wrapt (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy>=3.0.6->fastcoref)\n",
      "  Downloading wrapt-2.0.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from torch>=1.10.0->fastcoref) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from torch>=1.10.0->fastcoref) (3.6.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.10.0->fastcoref) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from transformers>=4.11.3->fastcoref) (2025.10.23)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from transformers>=4.11.3->fastcoref) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from transformers>=4.11.3->fastcoref) (0.7.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from anyio->httpx<1.0.0->datasets>=2.5.2->fastcoref) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from jinja2->spacy>=3.0.6->fastcoref) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from pandas->datasets>=2.5.2->fastcoref) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from pandas->datasets>=2.5.2->fastcoref) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from pandas->datasets>=2.5.2->fastcoref) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.5.2->fastcoref) (1.17.0)\n",
      "Downloading datasets-4.5.0-py3-none-any.whl (515 kB)\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Downloading fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "Downloading multiprocess-0.70.18-py313-none-any.whl (151 kB)\n",
      "Downloading scipy-1.17.0-cp313-cp313-macosx_14_0_arm64.whl (20.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading spacy-3.8.11-cp313-cp313-macosx_11_0_arm64.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.13-cp313-cp313-macosx_11_0_arm64.whl (42 kB)\n",
      "Downloading murmurhash-1.0.15-cp313-cp313-macosx_11_0_arm64.whl (27 kB)\n",
      "Downloading preshed-3.0.12-cp313-cp313-macosx_11_0_arm64.whl (122 kB)\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.2-cp313-cp313-macosx_11_0_arm64.whl (651 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m651.7/651.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading thinc-8.3.10-cp313-cp313-macosx_11_0_arm64.whl (737 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m737.1/737.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading blis-1.3.3-cp313-cp313-macosx_11_0_arm64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading typer_slim-0.21.1-py3-none-any.whl (47 kB)\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.3-py3-none-any.whl (50 kB)\n",
      "Downloading cloudpathlib-0.23.0-py3-none-any.whl (62 kB)\n",
      "Downloading smart_open-7.5.0-py3-none-any.whl (63 kB)\n",
      "Downloading wrapt-2.0.1-cp313-cp313-macosx_11_0_arm64.whl (61 kB)\n",
      "Building wheels for collected packages: fastcoref\n",
      "  Building wheel for fastcoref (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fastcoref: filename=fastcoref-2.1.6-py3-none-any.whl size=31333 sha256=c747ca5006f95c520d5cc6a1ba257b502d2cc7bfd99d73680b0f308987411dc8\n",
      "  Stored in directory: /Users/gurusai/Library/Caches/pip/wheels/28/fa/c6/de27e69bf4a85dd71ad99ff2a8b12d6de77227310794c557aa\n",
      "Successfully built fastcoref\n",
      "Installing collected packages: wrapt, wasabi, typer-slim, spacy-loggers, spacy-legacy, scipy, murmurhash, fsspec, dill, cymem, cloudpathlib, catalogue, blis, srsly, smart-open, preshed, multiprocess, confection, weasel, thinc, datasets, spacy, fastcoref\n",
      "\u001b[2K  Attempting uninstall: fsspec\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/23\u001b[0m [scipy]\n",
      "\u001b[2K    Found existing installation: fsspec 2026.1.0━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/23\u001b[0m [scipy]\n",
      "\u001b[2K    Uninstalling fsspec-2026.1.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/23\u001b[0m [scipy]\n",
      "\u001b[2K      Successfully uninstalled fsspec-2026.1.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/23\u001b[0m [scipy]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/23\u001b[0m [fastcoref]23\u001b[0m [spacy]ts]lib]\n",
      "\u001b[1A\u001b[2KSuccessfully installed blis-1.3.3 catalogue-2.0.10 cloudpathlib-0.23.0 confection-0.1.5 cymem-2.0.13 datasets-4.5.0 dill-0.4.0 fastcoref-2.1.6 fsspec-2025.10.0 multiprocess-0.70.18 murmurhash-1.0.15 preshed-3.0.12 scipy-1.17.0 smart-open-7.5.0 spacy-3.8.11 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.2 thinc-8.3.10 typer-slim-0.21.1 wasabi-1.1.3 weasel-0.4.3 wrapt-2.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install fastcoref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c99ac47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/23/2026 14:19:27 - INFO - \t missing_keys: []\n",
      "01/23/2026 14:19:27 - INFO - \t unexpected_keys: []\n",
      "01/23/2026 14:19:27 - INFO - \t mismatched_keys: []\n",
      "01/23/2026 14:19:27 - INFO - \t error_msgs: []\n",
      "01/23/2026 14:19:27 - INFO - \t Model Parameters: 90.5M, Transformer: 82.1M, Coref head: 8.4M\n",
      "01/23/2026 14:19:27 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 154.99 examples/s]\n",
      "01/23/2026 14:19:27 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 28.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Entity Chain: ['U.S. President Donald Trump', 'he', 'his']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from fastcoref import FCoref\n",
    "\n",
    "# 1. Load the model (optimized for speed)\n",
    "model = FCoref(device='cpu') # Use 'cuda:0' if you have a GPU\n",
    "\n",
    "text = \"U.S. President Donald Trump barrels into Davos, Switzerland, on Wednesday, where he is likely to escalate his push for acquiring Greenland despite European protests in the biggest fraying of transatlantic ties in decades.\"\n",
    "\n",
    "# 2. Predict Clusters\n",
    "preds = model.predict(texts=[text])\n",
    "clusters = preds[0].get_clusters(as_strings=True)\n",
    "\n",
    "# Output: [['U.S. President Donald Trump', 'he', 'his']]\n",
    "print(f\"Detected Entity Chain: {clusters[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d737707",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "LongformerModel does not support an attention implementation through torch.nn.functional.scaled_dot_product_attention yet. Please request the support for this architecture: https://github.com/huggingface/transformers/issues/28005. If you believe this error is a bug, please open an issue in Transformers GitHub repository and load your model with the argument `attn_implementation=\"eager\"` meanwhile. Example: `model = AutoModel.from_pretrained(\"openai/whisper-tiny\", attn_implementation=\"eager\")`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfastcoref\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LingMessCoref\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Load the SOTA model (LingMess) instead of the distilled one\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m model = \u001b[43mLingMessCoref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m text = \u001b[33m\"\"\"\u001b[39m\u001b[33mU.S. President Donald Trump barrels into Davos, Switzerland, on Wednesday, where he is likely to escalate his push for acquiring Greenland despite European protests in the biggest fraying of transatlantic ties in decades.\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[33mTrump, who marked the end of his turbulent first year in office on Tuesday, is expected to overshadow the annual World Economic Forum (WEF) gathering where global elites discuss economic and political trends in the Swiss mountain resort.\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# 2. Predict Clusters\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/fastcoref/modeling.py:285\u001b[39m, in \u001b[36mLingMessCoref.__init__\u001b[39m\u001b[34m(self, model_name_or_path, device, nlp, enable_progress_bar)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_name_or_path=\u001b[33m'\u001b[39m\u001b[33mbiu-nlp/lingmess-coref\u001b[39m\u001b[33m'\u001b[39m, device=\u001b[38;5;28;01mNone\u001b[39;00m, nlp=\u001b[33m\"\u001b[39m\u001b[33men_core_web_sm\u001b[39m\u001b[33m\"\u001b[39m, enable_progress_bar=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLingMessModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPadCollator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable_progress_bar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnlp\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/fastcoref/modeling.py:111\u001b[39m, in \u001b[36mCorefModel.__init__\u001b[39m\u001b[34m(self, model_name_or_path, coref_class, collator_class, enable_progress_bar, device, nlp)\u001b[39m\n\u001b[32m    108\u001b[39m         download(nlp)\n\u001b[32m    109\u001b[39m         \u001b[38;5;28mself\u001b[39m.nlp = spacy.load(nlp, exclude=[\u001b[33m\"\u001b[39m\u001b[33mtagger\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mparser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlemmatizer\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mner\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtextcat\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m \u001b[38;5;28mself\u001b[39m.model, loading_info = \u001b[43mcoref_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_loading_info\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    114\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[38;5;28mself\u001b[39m.model.to(\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m loading_info.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/transformers/modeling_utils.py:277\u001b[39m, in \u001b[36mrestore_default_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    275\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    279\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/transformers/modeling_utils.py:4971\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4968\u001b[39m config = copy.deepcopy(config)  \u001b[38;5;66;03m# We do not want to modify the config inplace in from_pretrained.\u001b[39;00m\n\u001b[32m   4969\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ContextManagers(model_init_context):\n\u001b[32m   4970\u001b[39m     \u001b[38;5;66;03m# Let's make sure we don't run the init function of buffer modules\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4971\u001b[39m     model = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4973\u001b[39m \u001b[38;5;66;03m# Make sure to tie the weights correctly\u001b[39;00m\n\u001b[32m   4974\u001b[39m model.tie_weights()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/fastcoref/coref_models/modeling_lingmess.py:48\u001b[39m, in \u001b[36mLingMessModel.__init__\u001b[39m\u001b[34m(self, config)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28mself\u001b[39m.all_cats_size = \u001b[38;5;28mself\u001b[39m.ffnn_size * \u001b[38;5;28mself\u001b[39m.num_cats\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# this is how huggingface loading the class model and setting the name of the variable.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m base_model = \u001b[43mAutoModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m LingMessModel.base_model_prefix = base_model.base_model_prefix\n\u001b[32m     50\u001b[39m LingMessModel.config_class = base_model.config_class\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/transformers/models/auto/auto_factory.py:456\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_config\u001b[39m\u001b[34m(cls, config, **kwargs)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._model_mapping:\n\u001b[32m    455\u001b[39m     model_class = _get_model_class(config, \u001b[38;5;28mcls\u001b[39m._model_mapping)\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    459\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    460\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    461\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/transformers/modeling_utils.py:277\u001b[39m, in \u001b[36mrestore_default_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    275\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    279\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/transformers/modeling_utils.py:2311\u001b[39m, in \u001b[36mPreTrainedModel._from_config\u001b[39m\u001b[34m(cls, config, **kwargs)\u001b[39m\n\u001b[32m   2308\u001b[39m         model = \u001b[38;5;28mcls\u001b[39m(config, **kwargs)\n\u001b[32m   2310\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2311\u001b[39m     model = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2313\u001b[39m \u001b[38;5;66;03m# restore default dtype if it was modified\u001b[39;00m\n\u001b[32m   2314\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/transformers/models/longformer/modeling_longformer.py:1396\u001b[39m, in \u001b[36mLongformerModel.__init__\u001b[39m\u001b[34m(self, config, add_pooling_layer)\u001b[39m\n\u001b[32m   1391\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config, add_pooling_layer=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m   1392\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1393\u001b[39m \u001b[33;03m    add_pooling_layer (bool, *optional*, defaults to `True`):\u001b[39;00m\n\u001b[32m   1394\u001b[39m \u001b[33;03m        Whether to add a pooling layer\u001b[39;00m\n\u001b[32m   1395\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1396\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1397\u001b[39m     \u001b[38;5;28mself\u001b[39m.config = config\n\u001b[32m   1399\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config.attention_window, \u001b[38;5;28mint\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/transformers/modeling_utils.py:2076\u001b[39m, in \u001b[36mPreTrainedModel.__init__\u001b[39m\u001b[34m(self, config, *inputs, **kwargs)\u001b[39m\n\u001b[32m   2072\u001b[39m \u001b[38;5;28mself\u001b[39m.config = config\n\u001b[32m   2074\u001b[39m \u001b[38;5;66;03m# Check the attention implementation is supported, or set it if not yet set (on the internal attr, to avoid\u001b[39;00m\n\u001b[32m   2075\u001b[39m \u001b[38;5;66;03m# setting it recursively)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2076\u001b[39m \u001b[38;5;28mself\u001b[39m.config._attn_implementation_internal = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_and_adjust_attn_implementation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2077\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_attn_implementation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_init_check\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m   2078\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2080\u001b[39m \u001b[38;5;66;03m# for initialization of the loss\u001b[39;00m\n\u001b[32m   2081\u001b[39m loss_type = \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/transformers/modeling_utils.py:2686\u001b[39m, in \u001b[36mPreTrainedModel._check_and_adjust_attn_implementation\u001b[39m\u001b[34m(self, attn_implementation, is_init_check)\u001b[39m\n\u001b[32m   2684\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   2685\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2686\u001b[39m     applicable_attn_implementation = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_correct_attn_implementation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2687\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapplicable_attn_implementation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_init_check\u001b[49m\n\u001b[32m   2688\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2689\u001b[39m     \u001b[38;5;66;03m# preload flash attention here to allow compile with fullgraph\u001b[39;00m\n\u001b[32m   2690\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m applicable_attn_implementation.startswith(\u001b[33m\"\u001b[39m\u001b[33mflash_attention\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/transformers/modeling_utils.py:2725\u001b[39m, in \u001b[36mPreTrainedModel.get_correct_attn_implementation\u001b[39m\u001b[34m(self, requested_attention, is_init_check)\u001b[39m\n\u001b[32m   2723\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   2724\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m requested_attention == \u001b[33m\"\u001b[39m\u001b[33msdpa\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2725\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   2726\u001b[39m         applicable_attention = \u001b[33m\"\u001b[39m\u001b[33meager\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2728\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m applicable_attention\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/transformers/modeling_utils.py:2722\u001b[39m, in \u001b[36mPreTrainedModel.get_correct_attn_implementation\u001b[39m\u001b[34m(self, requested_attention, is_init_check)\u001b[39m\n\u001b[32m   2719\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m applicable_attention == \u001b[33m\"\u001b[39m\u001b[33msdpa\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2720\u001b[39m     \u001b[38;5;66;03m# Sdpa is the default, so we try it and fallback to eager otherwise when not possible\u001b[39;00m\n\u001b[32m   2721\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2722\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sdpa_can_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_init_check\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2723\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   2724\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m requested_attention == \u001b[33m\"\u001b[39m\u001b[33msdpa\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/transformers/modeling_utils.py:2574\u001b[39m, in \u001b[36mPreTrainedModel._sdpa_can_dispatch\u001b[39m\u001b[34m(self, is_init_check)\u001b[39m\n\u001b[32m   2563\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2564\u001b[39m \u001b[33;03mCheck the availability of SDPA for a given model.\u001b[39;00m\n\u001b[32m   2565\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2571\u001b[39m \u001b[33;03m        before instantiating the full models if we know that the model does not support the requested attention.\u001b[39;00m\n\u001b[32m   2572\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2573\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._supports_sdpa:\n\u001b[32m-> \u001b[39m\u001b[32m2574\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2575\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not support an attention implementation through torch.nn.functional.scaled_dot_product_attention yet.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2576\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m Please request the support for this architecture: https://github.com/huggingface/transformers/issues/28005. If you believe\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2577\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m this error is a bug, please open an issue in Transformers GitHub repository and load your model with the argument `attn_implementation=\u001b[39m\u001b[33m\"\u001b[39m\u001b[33meager\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m` meanwhile. Example: `model = AutoModel.from_pretrained(\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mopenai/whisper-tiny\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m, attn_implementation=\u001b[39m\u001b[33m\"\u001b[39m\u001b[33meager\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m)`\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   2578\u001b[39m     )\n\u001b[32m   2580\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2581\u001b[39m     torch.version.hip \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2582\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m torch.cuda.device_count() > \u001b[32m1\u001b[39m\n\u001b[32m   2583\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m version.parse(torch.__version__) < version.parse(\u001b[33m\"\u001b[39m\u001b[33m2.4.1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2584\u001b[39m ):\n\u001b[32m   2585\u001b[39m     logger.warning_once(\n\u001b[32m   2586\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUsing the `SDPA` attention implementation on multi-gpu setup with ROCM may lead to performance issues due to the FA backend. Disabling it to use alternative backends.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2587\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: LongformerModel does not support an attention implementation through torch.nn.functional.scaled_dot_product_attention yet. Please request the support for this architecture: https://github.com/huggingface/transformers/issues/28005. If you believe this error is a bug, please open an issue in Transformers GitHub repository and load your model with the argument `attn_implementation=\"eager\"` meanwhile. Example: `model = AutoModel.from_pretrained(\"openai/whisper-tiny\", attn_implementation=\"eager\")`"
     ]
    }
   ],
   "source": [
    "from fastcoref import LingMessCoref\n",
    "\n",
    "# Load the SOTA model (LingMess) instead of the distilled one\n",
    "model = LingMessCoref(device='cpu')\n",
    "text = \"\"\"U.S. President Donald Trump barrels into Davos, Switzerland, on Wednesday, where he is likely to escalate his push for acquiring Greenland despite European protests in the biggest fraying of transatlantic ties in decades.\n",
    "Trump, who marked the end of his turbulent first year in office on Tuesday, is expected to overshadow the annual World Economic Forum (WEF) gathering where global elites discuss economic and political trends in the Swiss mountain resort.\n",
    "\"\"\"\n",
    "# 2. Predict Clusters\n",
    "preds = model.predict(texts=[text])\n",
    "clusters = preds[0].get_clusters(as_strings=True)\n",
    "print(f\"Detected Entity Chain: {clusters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59a74e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcoref import LingMessCoref\n",
    "\n",
    "model = LingMessCoref(device='cpu')\n",
    "text = \"\"\"U.S. President Donald Trump barrels into Davos, Switzerland, on Wednesday, where he is likely to escalate his push for acquiring Greenland despite European protests in the biggest fraying of transatlantic ties in decades.\n",
    "Trump, who marked the end of his turbulent first year in office on Tuesday, is expected to overshadow the annual World Economic Forum (WEF) gathering where global elites discuss economic and political trends in the Swiss mountain resort.\n",
    "\"\"\"\n",
    "preds = model.predict(texts=[text])\n",
    "clusters = preds[0].get_clusters(as_strings=True)\n",
    "print(f\"Detected Entity Chain: {clusters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98964cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 54899.27it/s]\n",
      "01/23/2026 14:40:54 - INFO - \t Loading the following GLiNER type: <class 'gliner.model.UniEncoderSpanGLiNER'>...\n",
      "01/23/2026 14:41:01 - INFO - \t missing_keys: []\n",
      "01/23/2026 14:41:01 - INFO - \t unexpected_keys: []\n",
      "01/23/2026 14:41:01 - INFO - \t mismatched_keys: []\n",
      "01/23/2026 14:41:01 - INFO - \t error_msgs: []\n",
      "01/23/2026 14:41:01 - INFO - \t Model Parameters: 90.5M, Transformer: 82.1M, Coref head: 8.4M\n",
      "01/23/2026 14:41:01 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 166.61 examples/s]\n",
      "01/23/2026 14:41:02 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 29.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'start': 15, 'end': 27, 'text': 'Donald Trump', 'label': 'person', 'score': 0.9866982102394104}, {'start': 41, 'end': 46, 'text': 'Davos', 'label': 'place', 'score': 0.9498966932296753}, {'start': 48, 'end': 59, 'text': 'Switzerland', 'label': 'place', 'score': 0.8984706401824951}, {'start': 129, 'end': 138, 'text': 'Greenland', 'label': 'place', 'score': 0.5037164092063904}]\n",
      "[['U.S. President Donald Trump', 'he', 'his']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from fastcoref import FCoref\n",
    "from gliner import GLiNER\n",
    "\n",
    "\n",
    "\n",
    "text = \"U.S. President Donald Trump barrels into Davos, Switzerland, on Wednesday, where he is likely to escalate his push for acquiring Greenland despite European protests in the biggest fraying of transatlantic ties in decades.\"\n",
    "\n",
    "model = GLiNER.from_pretrained(\"urchade/gliner_medium-v2.1\")\n",
    "labels = ['person','place','object']\n",
    "#labels = [\"Person\", \"Business Metric\", \"Strategic Move\"]\n",
    "entities = model.predict_entities(text, labels)\n",
    "# 1. Load the model (optimized for speed)\n",
    "model = FCoref(device='cpu') # Use 'cuda:0' if you have a GPU\n",
    "preds = model.predict(texts=[text])\n",
    "clusters = preds[0].get_clusters(as_strings=True)\n",
    "\n",
    "print(entities)\n",
    "print(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78699ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting setfit\n",
      "  Downloading setfit-1.1.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: datasets>=2.15.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from setfit) (4.5.0)\n",
      "Collecting sentence-transformers>=3 (from sentence-transformers[train]>=3->setfit)\n",
      "  Using cached sentence_transformers-5.2.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: transformers>=4.41.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from setfit) (4.57.6)\n",
      "Collecting evaluate>=0.3.0 (from setfit)\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: huggingface_hub>=0.24.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from setfit) (0.36.0)\n",
      "Collecting scikit-learn (from setfit)\n",
      "  Downloading scikit_learn-1.8.0-cp313-cp313-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from setfit) (24.2)\n",
      "Requirement already satisfied: filelock in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.15.0->setfit) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.15.0->setfit) (2.3.4)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.15.0->setfit) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.15.0->setfit) (0.4.0)\n",
      "Requirement already satisfied: pandas in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.15.0->setfit) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.15.0->setfit) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.15.0->setfit) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.15.0->setfit) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.15.0->setfit) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.15.0->setfit) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.15.0->setfit) (2025.10.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from datasets>=2.15.0->setfit) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.15.0->setfit) (3.13.2)\n",
      "Requirement already satisfied: anyio in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets>=2.15.0->setfit) (4.11.0)\n",
      "Requirement already satisfied: certifi in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets>=2.15.0->setfit) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets>=2.15.0->setfit) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets>=2.15.0->setfit) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.15.0->setfit) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from huggingface_hub>=0.24.0->setfit) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from huggingface_hub>=0.24.0->setfit) (1.2.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.15.0->setfit) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.15.0->setfit) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.15.0->setfit) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.15.0->setfit) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.15.0->setfit) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.15.0->setfit) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.15.0->setfit) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from requests>=2.32.2->datasets>=2.15.0->setfit) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from requests>=2.32.2->datasets>=2.15.0->setfit) (2.5.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (2.9.1)\n",
      "Requirement already satisfied: scipy in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (1.17.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from transformers>=4.41.0->setfit) (2025.10.23)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from transformers>=4.41.0->setfit) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from transformers>=4.41.0->setfit) (0.7.0)\n",
      "Collecting accelerate>=0.20.3 (from sentence-transformers[train]>=3->setfit)\n",
      "  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: psutil in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from accelerate>=0.20.3->sentence-transformers[train]>=3->setfit) (7.1.2)\n",
      "Requirement already satisfied: setuptools in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from anyio->httpx<1.0.0->datasets>=2.15.0->setfit) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from pandas->datasets>=2.15.0->setfit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from pandas->datasets>=2.15.0->setfit) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from pandas->datasets>=2.15.0->setfit) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.15.0->setfit) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.3.0 in /Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages (from scikit-learn->setfit) (1.5.2)\n",
      "Collecting threadpoolctl>=3.2.0 (from scikit-learn->setfit)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading setfit-1.1.3-py3-none-any.whl (75 kB)\n",
      "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
      "Using cached sentence_transformers-5.2.0-py3-none-any.whl (493 kB)\n",
      "Downloading accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
      "Downloading scikit_learn-1.8.0-cp313-cp313-macosx_12_0_arm64.whl (8.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scikit-learn, accelerate, sentence-transformers, evaluate, setfit\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6/6\u001b[0m [setfit]2m3/6\u001b[0m [sentence-transformers]\n",
      "\u001b[1A\u001b[2KSuccessfully installed accelerate-1.12.0 evaluate-0.4.6 scikit-learn-1.8.0 sentence-transformers-5.2.0 setfit-1.1.3 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install setfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39092e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4/4 [00:00<00:00, 773.25 examples/s]\n",
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
      "/var/folders/v8/1wyl6_ks02s620m7tv5drmch0000gn/T/ipykernel_8736/635375625.py:34: DeprecationWarning: `SetFitTrainer` has been deprecated and will be removed in v2.0.0 of SetFit. Please use `Trainer` instead.\n",
      "  trainer = SetFitTrainer(\n",
      "Map: 100%|██████████| 4/4 [00:00<00:00, 1582.16 examples/s]\n",
      "***** Running training *****\n",
      "  Num unique pairs = 160\n",
      "  Batch size = 16\n",
      "  Num epochs = 1\n",
      "/Users/gurusai/programming/PERSONAL_NEWS/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.173300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stance on 'Crypto Ban': Against\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from setfit import SetFitModel, SetFitTrainer\n",
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "\n",
    "# 1. Prepare your data (Simulated output from your GLiNER/Coref pipeline)\n",
    "# Note: You likely have this in a Pandas DataFrame already.\n",
    "data = [\n",
    "    {\"text\": \"Target: Interest Rates | Text: The fed's decision to hike rates is necessary to curb inflation.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Target: Interest Rates | Text: Higher rates are going to strangle the housing market completely.\", \"label\": \"Against\"},\n",
    "    {\"text\": \"Target: AI Regulation | Text: We need strict safety guardrails before deploying these models.\", \"label\": \"For\"},\n",
    "    {\"text\": \"Target: AI Regulation | Text: Over-regulation will only stifle innovation in the tech sector.\", \"label\": \"Against\"},\n",
    "    # ... add a few more examples per class ...\n",
    "]\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "dataset = Dataset.from_list(data)\n",
    "\n",
    "# Map labels to integers\n",
    "label_mapping = {\"Against\": 0, \"Neutral\": 1, \"For\": 2}\n",
    "def encode_labels(record):\n",
    "    return {\"label\": label_mapping[record[\"label\"]]}\n",
    "\n",
    "dataset = dataset.map(encode_labels)\n",
    "\n",
    "# 2. Load a Sentence Transformer model\n",
    "# 'paraphrase-mpnet-base-v2' is excellent for semantic understanding, \n",
    "# but for financial/news specific text, you might later try 'sentence-transformers/all-MiniLM-L6-v2' for speed.\n",
    "model = SetFitModel.from_pretrained(\n",
    "    \"sentence-transformers/paraphrase-mpnet-base-v2\",\n",
    "    labels=[\"Against\", \"Neutral\", \"For\"]\n",
    ")\n",
    "\n",
    "# 3. Initialize Trainer\n",
    "trainer = SetFitTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    loss_class=CosineSimilarityLoss, # The magic of SetFit: Contrastive Learning\n",
    "    batch_size=16,\n",
    "    num_iterations=20, # Generates 20 pairs per sentence for contrastive learning\n",
    "    num_epochs=1\n",
    ")\n",
    "\n",
    "# 4. Train\n",
    "trainer.train()\n",
    "\n",
    "# 5. Inference (Simulating your pipeline)\n",
    "target = \"Donald Trump\"\n",
    "sentence = \"U.S. President Donald Trump barrels into Davos, Switzerland, on Wednesday, where he is likely to escalate his push for acquiring Greenland despite European protests in the biggest fraying of transatlantic ties in decades.\"\n",
    "formatted_input = f\"Target: {target} | Text: {sentence}\"\n",
    "\n",
    "preds = model([formatted_input])\n",
    "print(f\"Stance on '{target}': {preds[0]}\")\n",
    "# Output: Stance on 'Crypto Ban': Against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04bef627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stance on 'Donald Trump': For\n"
     ]
    }
   ],
   "source": [
    "# 5. Inference (Simulating your pipeline)\n",
    "target = \"Donald Trump\"\n",
    "sentence = \"U.S. President Donald Trump barrels into Davos, Switzerland, on Wednesday, where he is likely to escalate his push for acquiring Greenland despite European protests in the biggest fraying of transatlantic ties in decades.\"\n",
    "formatted_input = f\"Target: {target} | Text: {sentence}\"\n",
    "\n",
    "preds = model([formatted_input])\n",
    "print(f\"Stance on '{target}': {preds[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbbbb23",
   "metadata": {},
   "source": [
    "# sample article summary:\n",
    "Recovery efforts are underway after Hurricane Melissa left a path of devastation in the Caribbean this week.\n",
    "The United Nations said the damage in Jamaica, where the storm made landfall on Tuesday (October 28) as a Category 5 hurricane, was on a level \"never seen before.\" Cuba is also reported to be calculating cost of damages after homes collapsed and blocked roads, with an estimated 735,000 people reported to be in shelters and the full extent of damage undetermined.\n",
    "At least 31 people have died in relation to Hurricane Melissa's devastation across several countries. At least 25 people died and several remain trapped in homes in Petit-Goáve, Haiti, after a river was flooded by the powerful storm, Mayor Jean Bertrans Subrème told the Associated Press.\n",
    "“I am overwhelmed by the situation,” Subrème said, adding that he’d requested assistance from the government.\n",
    "At least three other deaths, including two caused by a landslide, were also reported in Haiti in relation to Hurricane Melissa, the Haitian Civil Protection Agency confirmed in a statement. At least one person has died in the Dominican Republic, according to officials, who confirmed more than 1,000 others were evacuated or displaced via CNN.\n",
    "Melissa made landfall in Cuba Wednesday (October 29) morning as an \"extremely dangerous\" Category 3, the National Hurricane Center in Miami confirmed via NBC News. The storm previously made landfall in Jamaica on Tuesday as a Category 5 at maximum sustained winds of 185 MPH, which tied with the Labor Day Hurricane of 1935 and Hurricane Dorian in 2019 in the Caribbean and the second-highest wind speed recorded in the Atlantic, behind only Hurricane Allen in 1980.\n",
    "Severe flooding was reported as heavy rains and strong winds hit the province, with more than 750,000 residents had evacuated their homes across the country. The storm was downgraded to Category 4 at 4:00 p.m. ET on Tuesday and a Category 3 early Wednesday morning.\n",
    "Jamaica was reported to have \"suffered major impact\" after the hurricane made landfall, with at least two or three hospitals suffering severe damage and housing expected to be \"severely impacted\" in the storm's path, Prime Minister Andrew Holness said via NBC News.\n",
    "\n",
    "so now, we figure out all the entities in this summary\n",
    "and we need to map the stance on each entity as pos neg or neutral \n",
    "\n",
    "so plan of action is, \n",
    "there's 3 ways of doing this\n",
    "1. sentence by sentence\n",
    "2. paragraph by paragraph\n",
    "3. as an entire passage. \n",
    "\n",
    "we'll go backwards. \n",
    "\n",
    "1. we need to train our SETFIT stance model to completion v1\n",
    "with sufficient models \n",
    "\n",
    "2. pass entire passage\n",
    "\n",
    "3. chunk passage into paragraphs and run it\n",
    "\n",
    "4. chunk each paragraph into sentences and chunk them, \n",
    "\n",
    "5. mix and match?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee164dbb",
   "metadata": {},
   "source": [
    "# Training SETFIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dd5966",
   "metadata": {},
   "outputs": [],
   "source": [
    "ß"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
